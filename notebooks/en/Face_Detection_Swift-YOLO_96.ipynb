{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDbwrjIj5zfR"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example 🔥 </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "956CDKeW5zfS"
      },
      "source": [
        "# Face Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/Face_Detection_Swift-YOLO_96.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [face detection](https://universe.roboflow.com/detection-02p2y/face-b3jhr/dataset/2)\n",
        "\n",
        "**Class:** `face`\n",
        "\n",
        "![Face Detection](https://files.seeedstudio.com/sscma/static/detection_face.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the face detection dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY-zDMJp5zfT"
      },
      "source": [
        "## ⚙️Prerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUxeK4wg5zfT",
        "outputId": "efad9752-3e13-44ff-c128-c322116e23a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ethos-u-vela'...\n",
            "remote: Counting objects: 80, done\u001b[K\n",
            "remote: Finding sources: 100% (10824/10824)\u001b[K\n",
            "remote: Total 10824 (delta 6916), reused 9357 (delta 6916)\u001b[K\n",
            "Receiving objects: 100% (10824/10824), 5.76 MiB | 12.43 MiB/s, done.\n",
            "Resolving deltas: 100% (6916/6916), done.\n",
            "/content/ethos-u-vela\n",
            "Processing /content/ethos-u-vela\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatbuffers==24.3.25 (from ethos-u-vela==4.1.1.dev18+g86ea209)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: numpy>1.10.0 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela==4.1.1.dev18+g86ea209) (2.0.2)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela==4.1.1.dev18+g86ea209) (5.4.0)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: ethos-u-vela\n",
            "  Building wheel for ethos-u-vela (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-4.1.1.dev18+g86ea209-cp311-cp311-linux_x86_64.whl size=1671008 sha256=8d0ed5333a3253c6a623fce9ab8d248cf9df57547418ea9f6ba083890a93239c\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/8d/f3/56b8fc1b5927beb7f3629d39480aaebf15c73f19e798948e1f\n",
            "Successfully built ethos-u-vela\n",
            "Installing collected packages: flatbuffers, ethos-u-vela\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "Successfully installed ethos-u-vela-4.1.1.dev18+g86ea209 flatbuffers-24.3.25\n",
            "/content\n",
            "Cloning into 'ModelAssistant'...\n",
            "remote: Enumerating objects: 15719, done.\u001b[K\n",
            "remote: Total 15719 (delta 0), reused 0 (delta 0), pack-reused 15719 (from 1)\u001b[K\n",
            "Receiving objects: 100% (15719/15719), 26.57 MiB | 23.37 MiB/s, done.\n",
            "Resolving deltas: 100% (9186/9186), done.\n",
            "/content/ModelAssistant\n",
            "Checking if CUDA available... \u001b[032mOK\u001b[m\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Installing base deps... Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from -r requirements/export.txt (line 2))\n",
            "  Downloading https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations<=1.3.1 (from -r requirements/base.txt (line 2))\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting libusb1 (from -r requirements/base.txt (line 3))\n",
            "  Downloading libusb1-3.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting cbor (from -r requirements/base.txt (line 7))\n",
            "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<2.0.0,>=1.23.0 (from -r requirements/base.txt (line 8))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 13)) (4.12.0.88)\n",
            "Collecting openmim>=0.3.7 (from -r requirements/base.txt (line 17))\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 18)) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 19)) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 20)) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 21)) (6.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 22)) (0.25.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 23)) (1.6.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 27)) (0.13.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 31)) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/base.txt (line 32)) (4.67.1)\n",
            "Collecting pyvww (from -r requirements/base.txt (line 36))\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pnnx==0.0.4 (from -r requirements/inference.txt (line 2))\n",
            "  Downloading pnnx-0.0.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting ncnn>=1.0.20230517 (from -r requirements/inference.txt (line 3))\n",
            "  Downloading ncnn-1.0.20250503-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (28 kB)\n",
            "Collecting onnx>=1.14.0 (from -r requirements/inference.txt (line 4))\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxmltools>=1.11.2 (from -r requirements/inference.txt (line 5))\n",
            "  Downloading onnxmltools-1.14.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting onnxruntime>=1.15.1 (from -r requirements/inference.txt (line 6))\n",
            "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting onnxsim>=0.4.33 (from -r requirements/inference.txt (line 7))\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements/inference.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/inference.txt (line 9)) (2.18.0)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.11/dist-packages (from -r requirements/export.txt (line 8)) (4.1.1.dev18+g86ea209)\n",
            "Collecting black>=23.3.0 (from -r requirements/tests.txt (line 1))\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort>=5.12.0 (from -r requirements/tests.txt (line 2))\n",
            "  Downloading isort-6.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pre-commit>=3.3.3 (from -r requirements/tests.txt (line 3))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.11/dist-packages (from -r requirements/tests.txt (line 4)) (0.12.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (1.16.0)\n",
            "Collecting qudida>=0.0.4 (from albumentations<=1.3.1->-r requirements/base.txt (line 2))\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from albumentations<=1.3.1->-r requirements/base.txt (line 2)) (4.12.0.88)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python>=4.9.0.80 (from -r requirements/base.txt (line 13))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 17)) (8.2.1)\n",
            "Collecting colorama (from openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 17)) (24.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 17)) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 17)) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->-r requirements/base.txt (line 17)) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 19)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 19)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements/base.txt (line 19)) (2025.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 22)) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 22)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 22)) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->-r requirements/base.txt (line 22)) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 23)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->-r requirements/base.txt (line 23)) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->-r requirements/base.txt (line 27)) (1.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (3.8.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (3.1.3)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from pyvww->-r requirements/base.txt (line 36)) (2.0.10)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from pyvww->-r requirements/base.txt (line 36)) (0.15.1)\n",
            "Collecting portalocker (from ncnn>=1.0.20230517->-r requirements/inference.txt (line 3))\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.14.0->-r requirements/inference.txt (line 4)) (4.14.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (1.17.2)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.37.1)\n",
            "Collecting ruamel.yaml>=0.16.12 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting igraph>=0.9 (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela->-r requirements/export.txt (line 8)) (5.4.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=23.3.0->-r requirements/tests.txt (line 1))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black>=23.3.0->-r requirements/tests.txt (line 1)) (4.3.8)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading virtualenv-20.33.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->-r requirements/base.txt (line 27)) (2.22)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.12.0->-r requirements/inference.txt (line 9)) (0.17.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.1.1 (from albumentations<=1.3.1->-r requirements/base.txt (line 2))\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 17)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 17)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 17)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim>=0.3.7->-r requirements/base.txt (line 17)) (2025.7.14)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->-r requirements/export.txt (line 2))\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->-r requirements/base.txt (line 31)) (3.0.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim>=0.3.7->-r requirements/base.txt (line 17)) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.15.1->-r requirements/inference.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->pyvww->-r requirements/base.txt (line 36)) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->pyvww->-r requirements/base.txt (line 36)) (18.1.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim>=0.3.7->-r requirements/base.txt (line 17)) (0.1.2)\n",
            "Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit>=3.3.3->-r requirements/tests.txt (line 3))\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging>=23.1 (from -r requirements/base.txt (line 18))\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=2.0.0->-r requirements/base.txt (line 19))\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting requests (from openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting rich (from openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting setuptools>=41.0.0 (from tensorboard>=2.12.3->-r requirements/base.txt (line 31))\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tqdm>=4.65.0 (from -r requirements/base.txt (line 32))\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->-r requirements/base.txt (line 17)) (43.0.3)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'pnnx' candidate (version 0.0.4 at https://files.pythonhosted.org/packages/2a/61/e70626f1e94026da417e6ecd5ad303d0ef3fe7a32fb3fff821bb07f1f4e2/pnnx-0.0.4-py3-none-any.whl (from https://pypi.org/simple/pnnx/))\n",
            "Reason for being yanked: <none given>\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading pnnx-0.0.4-py3-none-any.whl (49.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libusb1-3.3.1-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading ncnn-1.0.20250503-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxmltools-1.14.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.5/352.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isort-6.0.1-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.33.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading openxlab-0.1.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: cbor, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cbor: filename=cbor-1.0.0-cp311-cp311-linux_x86_64.whl size=53933 sha256=0385b6854f7eab0d8774f670c47950fdd17a393a629ef30e36d5912067fd4a07\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/6b/45/0c34253b1af07d1d9dc524f6d44d74a6b191c43152e6aaf641\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=644e450539c190d073a94639e0e17a1c214fa1198f2aec48e7d23dde00df74e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/79/aa/3671e313c27de35211d345d7a9d8ccb7dde515cf05edba75df\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535315 sha256=c37dd5f00bd629adb2e6bd93b8ca8aa0cde9b857ced96df50b200fa432cfd719\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/9a/95/60f111d2a488c5f7f7ed2a96ce407ea57ec7393ddfdec8c956\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31656 sha256=b58497d67ce05ed915b2157f8a5633b0128af388dbee58039d5c14d98347d6ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
            "Successfully built cbor oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: texttable, pytz, pnnx, libusb1, distlib, crcmod, cbor, urllib3, tqdm, setuptools, ruamel.yaml.clib, pycryptodome, portalocker, pathspec, packaging, ordered-set, numpy, nodeenv, mypy-extensions, jmespath, isort, igraph, identify, humanfriendly, filelock, colorama, cfgv, virtualenv, ruamel.yaml, rich, requests, opencv-python-headless, opencv-python, onnx, model-index, coloredlogs, black, TinyNeuralNetwork, pre-commit, onnxsim, onnxruntime, onnxmltools, ncnn, aliyun-python-sdk-core, qudida, aliyun-python-sdk-kms, oss2, albumentations, openxlab, opendatalab, openmim, pyvww\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\n",
            "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\n",
            "datasets 4.0.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TinyNeuralNetwork-0.1.1 albumentations-1.3.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 black-25.1.0 cbor-1.0.0 cfgv-3.4.0 colorama-0.4.6 coloredlogs-15.0.1 crcmod-1.7 distlib-0.4.0 filelock-3.14.0 humanfriendly-10.0 identify-2.6.12 igraph-0.11.9 isort-6.0.1 jmespath-0.10.0 libusb1-3.3.1 model-index-0.1.11 mypy-extensions-1.1.0 ncnn-1.0.20250503 nodeenv-1.9.1 numpy-1.26.4 onnx-1.18.0 onnxmltools-1.14.0 onnxruntime-1.22.1 onnxsim-0.4.36 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.2 ordered-set-4.1.0 oss2-2.17.0 packaging-24.2 pathspec-0.12.1 pnnx-0.0.4 portalocker-3.2.0 pre-commit-4.2.0 pycryptodome-3.23.0 pytz-2023.4 pyvww-0.1.1 qudida-0.0.4 requests-2.28.2 rich-13.4.2 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 setuptools-60.2.0 texttable-1.7.0 tqdm-4.65.2 urllib3-1.26.20 virtualenv-20.33.0\n",
            "Installing OpenMIM deps... \n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcls>=1.0.0.rc6 (from -r requirements/mmlab.txt (line 2))\n",
            "  Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting mmcv-full<=2.1.0 (from -r requirements/mmlab.txt (line 3))\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv_full-1.7.2-cp311-cp311-manylinux1_x86_64.whl (70.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmdet<3.1.0,>=3.0.0 (from -r requirements/mmlab.txt (line 4))\n",
            "  Downloading mmdet-3.0.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting mmengine>=0.8.2 (from -r requirements/mmlab.txt (line 5))\n",
            "  Downloading mmengine-0.10.7-py3-none-any.whl.metadata (20 kB)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.10.0)\n",
            "Collecting modelindex (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2))\n",
            "  Downloading modelindex-0.0.2-py3-none-any.whl.metadata (756 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (13.4.2)\n",
            "Collecting addict (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (6.0.2)\n",
            "Collecting yapf (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.11.0.86)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.0.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4)) (1.17.0)\n",
            "Collecting terminaltables (from mmdet<3.1.0,>=3.0.0->-r requirements/mmlab.txt (line 4))\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.8.2->-r requirements/mmlab.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv-full<=2.1.0->-r requirements/mmlab.txt (line 3)) (4.3.8)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (3.8.2)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (4.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from model-index->modelindex->mmcls>=1.0.0.rc6->-r requirements/mmlab.txt (line 2)) (8.2.1)\n",
            "Downloading mmcls-1.0.0rc6-py2.py3-none-any.whl (906 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.1/906.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmengine-0.10.7-py3-none-any.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.7/452.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading modelindex-0.0.2-py3-none-any.whl (2.1 kB)\n",
            "Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: addict, yapf, terminaltables, modelindex, mmcv-full, mmengine, mmdet, mmcls\n",
            "Successfully installed addict-2.4.0 mmcls-1.0.0rc6 mmcv-full-1.7.2 mmdet-3.0.0 mmengine-0.10.7 modelindex-0.0.2 terminaltables-3.1.10 yapf-0.43.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Collecting mmcv==2.0.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/mmcv-2.0.0-cp311-cp311-manylinux1_x86_64.whl (74.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (0.10.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (6.0.2)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (0.43.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.0.0) (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==2.0.0) (4.3.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.2.0->mmcv==2.0.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv==2.0.0) (1.17.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu117/torch2.0.0/index.html\n",
            "Obtaining file:///content/ModelAssistant\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (from sscma==2.0.0rc3)\n",
            "  Using cached https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl (416 kB)\n",
            "Requirement already satisfied: torch<=2.0.1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: torchaudio<=2.0.2 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (2.0.1)\n",
            "Requirement already satisfied: torchvision<=0.15.2 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.15.1)\n",
            "Requirement already satisfied: albumentations<=1.3.1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.3.1)\n",
            "Requirement already satisfied: libusb1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (3.3.1)\n",
            "Requirement already satisfied: cbor in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (4.11.0.86)\n",
            "Requirement already satisfied: openmim>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.3.9)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (24.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (6.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.25.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.6.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.13.1)\n",
            "Requirement already satisfied: tensorboard>=2.12.3 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (4.65.2)\n",
            "Requirement already satisfied: pyvww in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.1.1)\n",
            "Requirement already satisfied: pnnx==0.0.4 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: ncnn>=1.0.20230517 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.0.20250503)\n",
            "Requirement already satisfied: onnx>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.18.0)\n",
            "Requirement already satisfied: onnxmltools>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.14.0)\n",
            "Requirement already satisfied: onnxruntime>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.22.1)\n",
            "Requirement already satisfied: onnxsim>=0.4.33 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.4.36)\n",
            "Requirement already satisfied: protobuf>=4.23.3 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (5.29.5)\n",
            "Requirement already satisfied: tensorflow>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (2.18.0)\n",
            "Requirement already satisfied: ethos-u-vela in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (4.1.1.dev18+g86ea209)\n",
            "Requirement already satisfied: black>=23.3.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (25.1.0)\n",
            "Requirement already satisfied: isort>=5.12.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (6.0.1)\n",
            "Requirement already satisfied: pre-commit>=3.3.3 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (4.2.0)\n",
            "Requirement already satisfied: ruff>=0.0.275 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.12.5)\n",
            "Requirement already satisfied: mmcls>=1.0.0.rc6 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.0.0rc6)\n",
            "Requirement already satisfied: mmcv-full<=2.1.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (1.7.2)\n",
            "Requirement already satisfied: mmdet<3.1.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: mmengine>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from sscma==2.0.0rc3) (0.10.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (1.16.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from albumentations<=1.3.1->sscma==2.0.0rc3) (4.11.0.86)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (8.2.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (1.1.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black>=23.3.0->sscma==2.0.0rc3) (4.3.8)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.10.0)\n",
            "Requirement already satisfied: modelindex in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (13.4.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv-full<=2.1.0->sscma==2.0.0rc3) (0.43.0)\n",
            "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\n",
            "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.0.10)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (2.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (1.17.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.11/dist-packages (from mmdet<3.1.0,>=3.0.0->sscma==2.0.0rc3) (3.1.10)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.8.2->sscma==2.0.0rc3) (3.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (2.28.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.14.0->sscma==2.0.0rc3) (4.14.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.13.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.0.10)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (24.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim>=0.3.7->sscma==2.0.0rc3) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->sscma==2.0.0rc3) (2025.2)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (2.6.12)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=3.3.3->sscma==2.0.0rc3) (20.33.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.20.0->sscma==2.0.0rc3) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->sscma==2.0.0rc3) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->sscma==2.0.0rc3) (1.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.8.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (60.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.12.3->sscma==2.0.0rc3) (3.1.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (1.17.2)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.12.0->sscma==2.0.0rc3) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.0.1->sscma==2.0.0rc3) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.1->sscma==2.0.0rc3) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch<=2.0.1->sscma==2.0.0rc3) (18.1.8)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.11/dist-packages (from ethos-u-vela->sscma==2.0.0rc3) (5.4.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.12 in /usr/local/lib/python3.11/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.18.14)\n",
            "Requirement already satisfied: igraph>=0.9 in /usr/local/lib/python3.11/dist-packages (from TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.11.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->sscma==2.0.0rc3) (2.22)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from igraph>=0.9->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (1.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.12.0->sscma==2.0.0rc3) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.12.0->sscma==2.0.0rc3) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (3.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ncnn>=1.0.20230517->sscma==2.0.0rc3) (2025.7.14)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.16.12->TinyNeuralNetwork@ https://files.seeedstudio.com/sscma/library/TinyNeuralNetwork-0.1.1-py3-none-any.whl->sscma==2.0.0rc3) (0.2.12)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit>=3.3.3->sscma==2.0.0rc3) (0.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.3->sscma==2.0.0rc3) (3.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.15.1->sscma==2.0.0rc3) (10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.2.3)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from model-index->openmim>=0.3.7->sscma==2.0.0rc3) (4.1.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (3.23.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.15.1->sscma==2.0.0rc3) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmcls>=1.0.0.rc6->sscma==2.0.0rc3) (0.1.2)\n",
            "Requirement already satisfied: oss2~=2.17.0 in /usr/local/lib/python3.11/dist-packages (from openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.17.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (1.7)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (2.16.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim>=0.3.7->sscma==2.0.0rc3) (43.0.3)\n",
            "Building wheels for collected packages: sscma\n",
            "  Building editable for sscma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sscma: filename=sscma-2.0.0rc3-0.editable-py3-none-any.whl size=11327 sha256=c53a754d7b12d15d61a30022722bbc665c09fa6cdb27c7b5536205d416cef2fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-caip7taj/wheels/77/65/65/3cf7374f35df46f1e6f5e7eb61e0314007e6b21f24cb22c849\n",
            "Successfully built sscma\n",
            "Installing collected packages: sscma\n",
            "Successfully installed sscma-2.0.0rc3\n",
            "Finished setup... \u001b[032mOK\u001b[m\n"
          ]
        }
      ],
      "source": [
        "# Ethos-U-Vela need to be installed this way, or SSCMA does not work anymore...\n",
        "!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n",
        "%cd ethos-u-vela\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA8m5M1z5zfU"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV6gr3Yl5zfU",
        "outputId": "f85d555a-ef41-4412-ce28-1e9dfaad0056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-04 16:35:47--  https://files.seeedstudio.com/sscma/model_zoo/detection/face_detection/swift_yolo_1xb16_300e_coco_300_sha1_fe1d7dec30d62e583a7ccf717fd6585c792570bf.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 3.163.125.9, 3.163.125.62, 3.163.125.51, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|3.163.125.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19446955 (19M) [application/octet-stream]\n",
            "Saving to: ‘BokChoy_Disease_Swift-YOLO_96/pretrain.pth’\n",
            "\n",
            "BokChoy_Disease_Swi 100%[===================>]  18.55M  43.6MB/s    in 0.4s    \n",
            "\n",
            "2025-08-04 16:35:47 (43.6 MB/s) - ‘BokChoy_Disease_Swift-YOLO_96/pretrain.pth’ saved [19446955/19446955]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p BokChoy_Disease_Swift-YOLO_96\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/face_detection/swift_yolo_1xb16_300e_coco_300_sha1_fe1d7dec30d62e583a7ccf717fd6585c792570bf.pth -O BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO3soHig5zfU"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BegL7DV5zfU",
        "outputId": "b74b4ff7-680a-40ce-96c4-61e7983e9e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-04 16:35:48--  https://universe.roboflow.com/ds/tCPeEouXqt?key=uohxULat1Q\n",
            "Resolving universe.roboflow.com (universe.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to universe.roboflow.com (universe.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/WkD6BxrwXB8lhhXEHkyH/IqymQeay3NELvNPTkYeD/2/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20250804%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250804T163548Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=04a1c66ab3ef68b43a44735587f8f5780b50c9b72216cdf71a44270dbba4cc6d01cf343fcf859753a7ae33398317acd3658fe9fc14cc8ebca9b372791e03d9083262b6b43e998e45fcdbb2cac03ae6083c8d91661655e196984fda1c69e1d495fa375d9807a5bb4530c85a0490b4a679dd8767a64eb93d50737f14f08558eac1d4bd01ab029c883e9542cf5643fb3877a2cbea302550184846a8d236d595931740277961d795f0ad1135af25e2ce499adc91531e53a61a5d644c3dd1638da39b9dec032036006ead3bb7a86cad48d4c1796fafdc5981494323c0ca387838a037a49b42263c676517b88ce2e29bd15c8f36ac3141e0a694e7db1a4a3745dd6c7d [following]\n",
            "--2025-08-04 16:35:48--  https://storage.googleapis.com/roboflow-platform-regional-exports/WkD6BxrwXB8lhhXEHkyH/IqymQeay3NELvNPTkYeD/2/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20250804%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250804T163548Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=04a1c66ab3ef68b43a44735587f8f5780b50c9b72216cdf71a44270dbba4cc6d01cf343fcf859753a7ae33398317acd3658fe9fc14cc8ebca9b372791e03d9083262b6b43e998e45fcdbb2cac03ae6083c8d91661655e196984fda1c69e1d495fa375d9807a5bb4530c85a0490b4a679dd8767a64eb93d50737f14f08558eac1d4bd01ab029c883e9542cf5643fb3877a2cbea302550184846a8d236d595931740277961d795f0ad1135af25e2ce499adc91531e53a61a5d644c3dd1638da39b9dec032036006ead3bb7a86cad48d4c1796fafdc5981494323c0ca387838a037a49b42263c676517b88ce2e29bd15c8f36ac3141e0a694e7db1a4a3745dd6c7d\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.141.207, 74.125.137.207, 142.250.101.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.141.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 105643033 (101M) [application/zip]\n",
            "Saving to: ‘BokChoy_Disease_Swift-YOLO_96/dataset.zip’\n",
            "\n",
            "BokChoy_Disease_Swi 100%[===================>] 100.75M  44.6MB/s    in 2.3s    \n",
            "\n",
            "2025-08-04 16:35:51 (44.6 MB/s) - ‘BokChoy_Disease_Swift-YOLO_96/dataset.zip’ saved [105643033/105643033]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p BokChoy_Disease_Swift-YOLO_96/dataset\n",
        "!wget -c https://universe.roboflow.com/ds/tCPeEouXqt?key=uohxULat1Q -O BokChoy_Disease_Swift-YOLO_96/dataset.zip\n",
        "!unzip -q BokChoy_Disease_Swift-YOLO_96/dataset.zip -d BokChoy_Disease_Swift-YOLO_96/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POWi7yR45zfV"
      },
      "source": [
        "## 🚀Train a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRXLMTJ55zfV",
        "outputId": "a6b6f8dc-e813-4ebd-a320-8457fe6a7869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 96, 96]\n",
            "08/04 16:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 897853487\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 897853487\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 16:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_163600'}\n",
            "2025-08-04 16:36:03.915893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754325364.158044    3926 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754325364.225320    3926 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 16:36:04.737354: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 16:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 16:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[1, 3, 96, 96]\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::add encountered 24 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::max_pool2d encountered 3 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul encountered 18 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::meshgrid encountered 3 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::clone encountered 3 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::sub encountered 3 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::mul_ encountered 6 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "bbox_head.head_module.data_preprocessor, bbox_head.loss_bbox, bbox_head.loss_cls, bbox_head.loss_obj, data_preprocessor\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::batch_norm encountered 85 time(s)\n",
            "08/04 16:36:17 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Unsupported operator aten::upsample_nearest2d encountered 2 time(s)\n",
            "\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "|\u001b[1m \u001b[0m\u001b[1mmodule                   \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#parameters or shape\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#flops    \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m#activations\u001b[0m\u001b[1m \u001b[0m|\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "| model                     | 0.944M               | 31.354M    | 0.264M       |\n",
            "|  backbone                 |  0.66M               |  25.202M   |  0.217M      |\n",
            "|   backbone.stem.conv      |   1.76K              |   4.055M   |   36.864K    |\n",
            "|    backbone.stem.conv.co… |    1.728K            |    3.981M  |    36.864K   |\n",
            "|    backbone.stem.conv.no… |    32                |    73.728K |    0         |\n",
            "|   backbone.stage1         |   9.216K             |   5.308M   |   82.944K    |\n",
            "|    backbone.stage1.0.conv |    3.504K            |    2.018M  |    13.824K   |\n",
            "|    backbone.stage1.1      |    5.712K            |    3.29M   |    69.12K    |\n",
            "|   backbone.stage2         |   36.56K             |   5.265M   |   51.84K     |\n",
            "|    backbone.stage2.0.conv |    8.72K             |    1.256M  |    5.76K     |\n",
            "|    backbone.stage2.1      |    27.84K            |    4.009M  |    46.08K    |\n",
            "|   backbone.stage3         |   0.188M             |   6.751M   |   34.56K     |\n",
            "|    backbone.stage3.0.conv |    28.96K            |    1.043M  |    2.88K     |\n",
            "|    backbone.stage3.1      |    0.159M            |    5.708M  |    31.68K    |\n",
            "|   backbone.stage4         |   0.425M             |   3.823M   |   10.8K      |\n",
            "|    backbone.stage4.0.conv |    0.116M            |    1.04M   |    1.44K     |\n",
            "|    backbone.stage4.1      |    0.245M            |    2.203M  |    7.2K      |\n",
            "|    backbone.stage4.2      |    64.48K            |    0.58M   |    2.16K     |\n",
            "|  neck                     |  0.279M              |  5.97M     |  43.2K       |\n",
            "|   neck.reduce_layers.2.c… |   12.96K             |   0.117M   |   0.72K      |\n",
            "|    neck.reduce_layers.2.… |    12.8K             |    0.115M  |    0.72K     |\n",
            "|    neck.reduce_layers.2.… |    0.16K             |    1.44K   |    0         |\n",
            "|   neck.top_down_layers    |   48K                |   2.704M   |   27.36K     |\n",
            "|    neck.top_down_layers.0 |    38.96K            |    1.403M  |    10.08K    |\n",
            "|    neck.top_down_layers.1 |    9.04K             |    1.302M  |    17.28K    |\n",
            "|   neck.downsample_layers  |   72.24K             |   1.041M   |   2.16K      |\n",
            "|    neck.downsample_layer… |    14.48K            |    0.521M  |    1.44K     |\n",
            "|    neck.downsample_layer… |    57.76K            |    0.52M   |    0.72K     |\n",
            "|   neck.bottom_up_layers   |   0.145M             |   2.1M     |   12.96K     |\n",
            "|    neck.bottom_up_layers… |    29.28K            |    1.054M  |    8.64K     |\n",
            "|    neck.bottom_up_layers… |    0.116M            |    1.045M  |    4.32K     |\n",
            "|   neck.upsample_layers    |                      |   8.64K    |   0          |\n",
            "|    neck.upsample_layers.0 |                      |    2.88K   |    0         |\n",
            "|    neck.upsample_layers.1 |                      |    5.76K   |    0         |\n",
            "|  bbox_head.head_module.c… |  5.094K              |  0.181M    |  3.402K      |\n",
            "|   bbox_head.head_module.… |   0.738K             |   0.104M   |   2.592K     |\n",
            "|    bbox_head.head_module… |    (18, 40, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module… |    (18,)             |            |              |\n",
            "|   bbox_head.head_module.… |   1.458K             |   51.84K   |   0.648K     |\n",
            "|    bbox_head.head_module… |    (18, 80, 1, 1)    |            |              |\n",
            "|    bbox_head.head_module… |    (18,)             |            |              |\n",
            "|   bbox_head.head_module.… |   2.898K             |   25.92K   |   0.162K     |\n",
            "|    bbox_head.head_module… |    (18, 160, 1, 1)   |            |              |\n",
            "|    bbox_head.head_module… |    (18,)             |            |              |\n",
            "+---------------------------+----------------------+------------+--------------+\n",
            "\n",
            "========================================\n",
            "    Input Shape     :   [1, 3, 96, 96]   \n",
            "    Model Flops     :      31.354M       \n",
            "  Model Parameters  :       0.944M       \n",
            "========================================\n",
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "08/04 16:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Optimizer groups: 88 .bias, 88 conv.weight, 85 other\n",
            "Loads checkpoint by local backend from path: BokChoy_Disease_Swift-YOLO_96/pretrain.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: backbone.stem.bn.weight, backbone.stem.bn.bias, backbone.stem.bn.running_mean, backbone.stem.bn.running_var, backbone.stem.bn.num_batches_tracked, backbone.stem.conv.weight, backbone.stage1.0.bn.weight, backbone.stage1.0.bn.bias, backbone.stage1.0.bn.running_mean, backbone.stage1.0.bn.running_var, backbone.stage1.0.bn.num_batches_tracked, backbone.stage1.0.conv.weight, backbone.stage1.1.main_conv.bn.weight, backbone.stage1.1.main_conv.bn.bias, backbone.stage1.1.main_conv.bn.running_mean, backbone.stage1.1.main_conv.bn.running_var, backbone.stage1.1.main_conv.bn.num_batches_tracked, backbone.stage1.1.short_conv.bn.weight, backbone.stage1.1.short_conv.bn.bias, backbone.stage1.1.short_conv.bn.running_mean, backbone.stage1.1.short_conv.bn.running_var, backbone.stage1.1.short_conv.bn.num_batches_tracked, backbone.stage1.1.final_conv.bn.weight, backbone.stage1.1.final_conv.bn.bias, backbone.stage1.1.final_conv.bn.running_mean, backbone.stage1.1.final_conv.bn.running_var, backbone.stage1.1.final_conv.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv1.bn.weight, backbone.stage1.1.blocks.0.conv1.bn.bias, backbone.stage1.1.blocks.0.conv1.bn.running_mean, backbone.stage1.1.blocks.0.conv1.bn.running_var, backbone.stage1.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage1.1.blocks.0.conv2.bn.weight, backbone.stage1.1.blocks.0.conv2.bn.bias, backbone.stage1.1.blocks.0.conv2.bn.running_mean, backbone.stage1.1.blocks.0.conv2.bn.running_var, backbone.stage1.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.0.bn.weight, backbone.stage2.0.bn.bias, backbone.stage2.0.bn.running_mean, backbone.stage2.0.bn.running_var, backbone.stage2.0.bn.num_batches_tracked, backbone.stage2.0.conv.weight, backbone.stage2.1.main_conv.bn.weight, backbone.stage2.1.main_conv.bn.bias, backbone.stage2.1.main_conv.bn.running_mean, backbone.stage2.1.main_conv.bn.running_var, backbone.stage2.1.main_conv.bn.num_batches_tracked, backbone.stage2.1.short_conv.bn.weight, backbone.stage2.1.short_conv.bn.bias, backbone.stage2.1.short_conv.bn.running_mean, backbone.stage2.1.short_conv.bn.running_var, backbone.stage2.1.short_conv.bn.num_batches_tracked, backbone.stage2.1.final_conv.bn.weight, backbone.stage2.1.final_conv.bn.bias, backbone.stage2.1.final_conv.bn.running_mean, backbone.stage2.1.final_conv.bn.running_var, backbone.stage2.1.final_conv.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv1.bn.weight, backbone.stage2.1.blocks.0.conv1.bn.bias, backbone.stage2.1.blocks.0.conv1.bn.running_mean, backbone.stage2.1.blocks.0.conv1.bn.running_var, backbone.stage2.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.0.conv2.bn.weight, backbone.stage2.1.blocks.0.conv2.bn.bias, backbone.stage2.1.blocks.0.conv2.bn.running_mean, backbone.stage2.1.blocks.0.conv2.bn.running_var, backbone.stage2.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv1.bn.weight, backbone.stage2.1.blocks.1.conv1.bn.bias, backbone.stage2.1.blocks.1.conv1.bn.running_mean, backbone.stage2.1.blocks.1.conv1.bn.running_var, backbone.stage2.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage2.1.blocks.1.conv2.bn.weight, backbone.stage2.1.blocks.1.conv2.bn.bias, backbone.stage2.1.blocks.1.conv2.bn.running_mean, backbone.stage2.1.blocks.1.conv2.bn.running_var, backbone.stage2.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.0.bn.weight, backbone.stage3.0.bn.bias, backbone.stage3.0.bn.running_mean, backbone.stage3.0.bn.running_var, backbone.stage3.0.bn.num_batches_tracked, backbone.stage3.0.conv.weight, backbone.stage3.1.main_conv.bn.weight, backbone.stage3.1.main_conv.bn.bias, backbone.stage3.1.main_conv.bn.running_mean, backbone.stage3.1.main_conv.bn.running_var, backbone.stage3.1.main_conv.bn.num_batches_tracked, backbone.stage3.1.short_conv.bn.weight, backbone.stage3.1.short_conv.bn.bias, backbone.stage3.1.short_conv.bn.running_mean, backbone.stage3.1.short_conv.bn.running_var, backbone.stage3.1.short_conv.bn.num_batches_tracked, backbone.stage3.1.final_conv.bn.weight, backbone.stage3.1.final_conv.bn.bias, backbone.stage3.1.final_conv.bn.running_mean, backbone.stage3.1.final_conv.bn.running_var, backbone.stage3.1.final_conv.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv1.bn.weight, backbone.stage3.1.blocks.0.conv1.bn.bias, backbone.stage3.1.blocks.0.conv1.bn.running_mean, backbone.stage3.1.blocks.0.conv1.bn.running_var, backbone.stage3.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.0.conv2.bn.weight, backbone.stage3.1.blocks.0.conv2.bn.bias, backbone.stage3.1.blocks.0.conv2.bn.running_mean, backbone.stage3.1.blocks.0.conv2.bn.running_var, backbone.stage3.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv1.bn.weight, backbone.stage3.1.blocks.1.conv1.bn.bias, backbone.stage3.1.blocks.1.conv1.bn.running_mean, backbone.stage3.1.blocks.1.conv1.bn.running_var, backbone.stage3.1.blocks.1.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.1.conv2.bn.weight, backbone.stage3.1.blocks.1.conv2.bn.bias, backbone.stage3.1.blocks.1.conv2.bn.running_mean, backbone.stage3.1.blocks.1.conv2.bn.running_var, backbone.stage3.1.blocks.1.conv2.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv1.bn.weight, backbone.stage3.1.blocks.2.conv1.bn.bias, backbone.stage3.1.blocks.2.conv1.bn.running_mean, backbone.stage3.1.blocks.2.conv1.bn.running_var, backbone.stage3.1.blocks.2.conv1.bn.num_batches_tracked, backbone.stage3.1.blocks.2.conv2.bn.weight, backbone.stage3.1.blocks.2.conv2.bn.bias, backbone.stage3.1.blocks.2.conv2.bn.running_mean, backbone.stage3.1.blocks.2.conv2.bn.running_var, backbone.stage3.1.blocks.2.conv2.bn.num_batches_tracked, backbone.stage4.0.bn.weight, backbone.stage4.0.bn.bias, backbone.stage4.0.bn.running_mean, backbone.stage4.0.bn.running_var, backbone.stage4.0.bn.num_batches_tracked, backbone.stage4.0.conv.weight, backbone.stage4.1.main_conv.bn.weight, backbone.stage4.1.main_conv.bn.bias, backbone.stage4.1.main_conv.bn.running_mean, backbone.stage4.1.main_conv.bn.running_var, backbone.stage4.1.main_conv.bn.num_batches_tracked, backbone.stage4.1.short_conv.bn.weight, backbone.stage4.1.short_conv.bn.bias, backbone.stage4.1.short_conv.bn.running_mean, backbone.stage4.1.short_conv.bn.running_var, backbone.stage4.1.short_conv.bn.num_batches_tracked, backbone.stage4.1.final_conv.bn.weight, backbone.stage4.1.final_conv.bn.bias, backbone.stage4.1.final_conv.bn.running_mean, backbone.stage4.1.final_conv.bn.running_var, backbone.stage4.1.final_conv.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv1.bn.weight, backbone.stage4.1.blocks.0.conv1.bn.bias, backbone.stage4.1.blocks.0.conv1.bn.running_mean, backbone.stage4.1.blocks.0.conv1.bn.running_var, backbone.stage4.1.blocks.0.conv1.bn.num_batches_tracked, backbone.stage4.1.blocks.0.conv2.bn.weight, backbone.stage4.1.blocks.0.conv2.bn.bias, backbone.stage4.1.blocks.0.conv2.bn.running_mean, backbone.stage4.1.blocks.0.conv2.bn.running_var, backbone.stage4.1.blocks.0.conv2.bn.num_batches_tracked, backbone.stage4.2.conv1.bn.weight, backbone.stage4.2.conv1.bn.bias, backbone.stage4.2.conv1.bn.running_mean, backbone.stage4.2.conv1.bn.running_var, backbone.stage4.2.conv1.bn.num_batches_tracked, backbone.stage4.2.conv1.conv.weight, backbone.stage4.2.conv2.bn.weight, backbone.stage4.2.conv2.bn.bias, backbone.stage4.2.conv2.bn.running_mean, backbone.stage4.2.conv2.bn.running_var, backbone.stage4.2.conv2.bn.num_batches_tracked, backbone.stage4.2.conv2.conv.weight, neck.reduce_layers.2.bn.weight, neck.reduce_layers.2.bn.bias, neck.reduce_layers.2.bn.running_mean, neck.reduce_layers.2.bn.running_var, neck.reduce_layers.2.bn.num_batches_tracked, neck.reduce_layers.2.conv.weight, neck.top_down_layers.0.0.main_conv.bn.weight, neck.top_down_layers.0.0.main_conv.bn.bias, neck.top_down_layers.0.0.main_conv.bn.running_mean, neck.top_down_layers.0.0.main_conv.bn.running_var, neck.top_down_layers.0.0.main_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.short_conv.bn.weight, neck.top_down_layers.0.0.short_conv.bn.bias, neck.top_down_layers.0.0.short_conv.bn.running_mean, neck.top_down_layers.0.0.short_conv.bn.running_var, neck.top_down_layers.0.0.short_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.final_conv.bn.weight, neck.top_down_layers.0.0.final_conv.bn.bias, neck.top_down_layers.0.0.final_conv.bn.running_mean, neck.top_down_layers.0.0.final_conv.bn.running_var, neck.top_down_layers.0.0.final_conv.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv1.bn.weight, neck.top_down_layers.0.0.blocks.0.conv1.bn.bias, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.0.0.blocks.0.conv2.bn.weight, neck.top_down_layers.0.0.blocks.0.conv2.bn.bias, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.bn.running_var, neck.top_down_layers.0.0.blocks.0.conv2.bn.num_batches_tracked, neck.top_down_layers.0.1.bn.weight, neck.top_down_layers.0.1.bn.bias, neck.top_down_layers.0.1.bn.running_mean, neck.top_down_layers.0.1.bn.running_var, neck.top_down_layers.0.1.bn.num_batches_tracked, neck.top_down_layers.0.1.conv.weight, neck.top_down_layers.1.main_conv.bn.weight, neck.top_down_layers.1.main_conv.bn.bias, neck.top_down_layers.1.main_conv.bn.running_mean, neck.top_down_layers.1.main_conv.bn.running_var, neck.top_down_layers.1.main_conv.bn.num_batches_tracked, neck.top_down_layers.1.short_conv.bn.weight, neck.top_down_layers.1.short_conv.bn.bias, neck.top_down_layers.1.short_conv.bn.running_mean, neck.top_down_layers.1.short_conv.bn.running_var, neck.top_down_layers.1.short_conv.bn.num_batches_tracked, neck.top_down_layers.1.final_conv.bn.weight, neck.top_down_layers.1.final_conv.bn.bias, neck.top_down_layers.1.final_conv.bn.running_mean, neck.top_down_layers.1.final_conv.bn.running_var, neck.top_down_layers.1.final_conv.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv1.bn.weight, neck.top_down_layers.1.blocks.0.conv1.bn.bias, neck.top_down_layers.1.blocks.0.conv1.bn.running_mean, neck.top_down_layers.1.blocks.0.conv1.bn.running_var, neck.top_down_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.top_down_layers.1.blocks.0.conv2.bn.weight, neck.top_down_layers.1.blocks.0.conv2.bn.bias, neck.top_down_layers.1.blocks.0.conv2.bn.running_mean, neck.top_down_layers.1.blocks.0.conv2.bn.running_var, neck.top_down_layers.1.blocks.0.conv2.bn.num_batches_tracked, neck.downsample_layers.0.bn.weight, neck.downsample_layers.0.bn.bias, neck.downsample_layers.0.bn.running_mean, neck.downsample_layers.0.bn.running_var, neck.downsample_layers.0.bn.num_batches_tracked, neck.downsample_layers.0.conv.weight, neck.downsample_layers.1.bn.weight, neck.downsample_layers.1.bn.bias, neck.downsample_layers.1.bn.running_mean, neck.downsample_layers.1.bn.running_var, neck.downsample_layers.1.bn.num_batches_tracked, neck.downsample_layers.1.conv.weight, neck.bottom_up_layers.0.main_conv.bn.weight, neck.bottom_up_layers.0.main_conv.bn.bias, neck.bottom_up_layers.0.main_conv.bn.running_mean, neck.bottom_up_layers.0.main_conv.bn.running_var, neck.bottom_up_layers.0.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.short_conv.bn.weight, neck.bottom_up_layers.0.short_conv.bn.bias, neck.bottom_up_layers.0.short_conv.bn.running_mean, neck.bottom_up_layers.0.short_conv.bn.running_var, neck.bottom_up_layers.0.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.final_conv.bn.weight, neck.bottom_up_layers.0.final_conv.bn.bias, neck.bottom_up_layers.0.final_conv.bn.running_mean, neck.bottom_up_layers.0.final_conv.bn.running_var, neck.bottom_up_layers.0.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv1.bn.weight, neck.bottom_up_layers.0.blocks.0.conv1.bn.bias, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.0.blocks.0.conv2.bn.weight, neck.bottom_up_layers.0.blocks.0.conv2.bn.bias, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.0.blocks.0.conv2.bn.num_batches_tracked, neck.bottom_up_layers.1.main_conv.bn.weight, neck.bottom_up_layers.1.main_conv.bn.bias, neck.bottom_up_layers.1.main_conv.bn.running_mean, neck.bottom_up_layers.1.main_conv.bn.running_var, neck.bottom_up_layers.1.main_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.short_conv.bn.weight, neck.bottom_up_layers.1.short_conv.bn.bias, neck.bottom_up_layers.1.short_conv.bn.running_mean, neck.bottom_up_layers.1.short_conv.bn.running_var, neck.bottom_up_layers.1.short_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.final_conv.bn.weight, neck.bottom_up_layers.1.final_conv.bn.bias, neck.bottom_up_layers.1.final_conv.bn.running_mean, neck.bottom_up_layers.1.final_conv.bn.running_var, neck.bottom_up_layers.1.final_conv.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv1.bn.weight, neck.bottom_up_layers.1.blocks.0.conv1.bn.bias, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv1.bn.num_batches_tracked, neck.bottom_up_layers.1.blocks.0.conv2.bn.weight, neck.bottom_up_layers.1.blocks.0.conv2.bn.bias, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.bn.running_var, neck.bottom_up_layers.1.blocks.0.conv2.bn.num_batches_tracked\n",
            "\n",
            "missing keys in source state_dict: backbone.stem.conv.conv.weight, backbone.stem.conv.norm.weight, backbone.stem.conv.norm.bias, backbone.stem.conv.norm.running_mean, backbone.stem.conv.norm.running_var, backbone.stage1.0.conv.conv.weight, backbone.stage1.0.conv.norm.weight, backbone.stage1.0.conv.norm.bias, backbone.stage1.0.conv.norm.running_mean, backbone.stage1.0.conv.norm.running_var, backbone.stage1.1.main_conv.norm.weight, backbone.stage1.1.main_conv.norm.bias, backbone.stage1.1.main_conv.norm.running_mean, backbone.stage1.1.main_conv.norm.running_var, backbone.stage1.1.short_conv.norm.weight, backbone.stage1.1.short_conv.norm.bias, backbone.stage1.1.short_conv.norm.running_mean, backbone.stage1.1.short_conv.norm.running_var, backbone.stage1.1.final_conv.norm.weight, backbone.stage1.1.final_conv.norm.bias, backbone.stage1.1.final_conv.norm.running_mean, backbone.stage1.1.final_conv.norm.running_var, backbone.stage1.1.blocks.0.conv1.norm.weight, backbone.stage1.1.blocks.0.conv1.norm.bias, backbone.stage1.1.blocks.0.conv1.norm.running_mean, backbone.stage1.1.blocks.0.conv1.norm.running_var, backbone.stage1.1.blocks.0.conv2.norm.weight, backbone.stage1.1.blocks.0.conv2.norm.bias, backbone.stage1.1.blocks.0.conv2.norm.running_mean, backbone.stage1.1.blocks.0.conv2.norm.running_var, backbone.stage1.1.blocks.1.conv1.conv.weight, backbone.stage1.1.blocks.1.conv1.norm.weight, backbone.stage1.1.blocks.1.conv1.norm.bias, backbone.stage1.1.blocks.1.conv1.norm.running_mean, backbone.stage1.1.blocks.1.conv1.norm.running_var, backbone.stage1.1.blocks.1.conv2.conv.weight, backbone.stage1.1.blocks.1.conv2.norm.weight, backbone.stage1.1.blocks.1.conv2.norm.bias, backbone.stage1.1.blocks.1.conv2.norm.running_mean, backbone.stage1.1.blocks.1.conv2.norm.running_var, backbone.stage1.1.blocks.2.conv1.conv.weight, backbone.stage1.1.blocks.2.conv1.norm.weight, backbone.stage1.1.blocks.2.conv1.norm.bias, backbone.stage1.1.blocks.2.conv1.norm.running_mean, backbone.stage1.1.blocks.2.conv1.norm.running_var, backbone.stage1.1.blocks.2.conv2.conv.weight, backbone.stage1.1.blocks.2.conv2.norm.weight, backbone.stage1.1.blocks.2.conv2.norm.bias, backbone.stage1.1.blocks.2.conv2.norm.running_mean, backbone.stage1.1.blocks.2.conv2.norm.running_var, backbone.stage2.0.conv.conv.weight, backbone.stage2.0.conv.norm.weight, backbone.stage2.0.conv.norm.bias, backbone.stage2.0.conv.norm.running_mean, backbone.stage2.0.conv.norm.running_var, backbone.stage2.1.main_conv.norm.weight, backbone.stage2.1.main_conv.norm.bias, backbone.stage2.1.main_conv.norm.running_mean, backbone.stage2.1.main_conv.norm.running_var, backbone.stage2.1.short_conv.norm.weight, backbone.stage2.1.short_conv.norm.bias, backbone.stage2.1.short_conv.norm.running_mean, backbone.stage2.1.short_conv.norm.running_var, backbone.stage2.1.final_conv.norm.weight, backbone.stage2.1.final_conv.norm.bias, backbone.stage2.1.final_conv.norm.running_mean, backbone.stage2.1.final_conv.norm.running_var, backbone.stage2.1.blocks.0.conv1.norm.weight, backbone.stage2.1.blocks.0.conv1.norm.bias, backbone.stage2.1.blocks.0.conv1.norm.running_mean, backbone.stage2.1.blocks.0.conv1.norm.running_var, backbone.stage2.1.blocks.0.conv2.norm.weight, backbone.stage2.1.blocks.0.conv2.norm.bias, backbone.stage2.1.blocks.0.conv2.norm.running_mean, backbone.stage2.1.blocks.0.conv2.norm.running_var, backbone.stage2.1.blocks.1.conv1.norm.weight, backbone.stage2.1.blocks.1.conv1.norm.bias, backbone.stage2.1.blocks.1.conv1.norm.running_mean, backbone.stage2.1.blocks.1.conv1.norm.running_var, backbone.stage2.1.blocks.1.conv2.norm.weight, backbone.stage2.1.blocks.1.conv2.norm.bias, backbone.stage2.1.blocks.1.conv2.norm.running_mean, backbone.stage2.1.blocks.1.conv2.norm.running_var, backbone.stage2.1.blocks.2.conv1.conv.weight, backbone.stage2.1.blocks.2.conv1.norm.weight, backbone.stage2.1.blocks.2.conv1.norm.bias, backbone.stage2.1.blocks.2.conv1.norm.running_mean, backbone.stage2.1.blocks.2.conv1.norm.running_var, backbone.stage2.1.blocks.2.conv2.conv.weight, backbone.stage2.1.blocks.2.conv2.norm.weight, backbone.stage2.1.blocks.2.conv2.norm.bias, backbone.stage2.1.blocks.2.conv2.norm.running_mean, backbone.stage2.1.blocks.2.conv2.norm.running_var, backbone.stage2.1.blocks.3.conv1.conv.weight, backbone.stage2.1.blocks.3.conv1.norm.weight, backbone.stage2.1.blocks.3.conv1.norm.bias, backbone.stage2.1.blocks.3.conv1.norm.running_mean, backbone.stage2.1.blocks.3.conv1.norm.running_var, backbone.stage2.1.blocks.3.conv2.conv.weight, backbone.stage2.1.blocks.3.conv2.norm.weight, backbone.stage2.1.blocks.3.conv2.norm.bias, backbone.stage2.1.blocks.3.conv2.norm.running_mean, backbone.stage2.1.blocks.3.conv2.norm.running_var, backbone.stage2.1.blocks.4.conv1.conv.weight, backbone.stage2.1.blocks.4.conv1.norm.weight, backbone.stage2.1.blocks.4.conv1.norm.bias, backbone.stage2.1.blocks.4.conv1.norm.running_mean, backbone.stage2.1.blocks.4.conv1.norm.running_var, backbone.stage2.1.blocks.4.conv2.conv.weight, backbone.stage2.1.blocks.4.conv2.norm.weight, backbone.stage2.1.blocks.4.conv2.norm.bias, backbone.stage2.1.blocks.4.conv2.norm.running_mean, backbone.stage2.1.blocks.4.conv2.norm.running_var, backbone.stage2.1.blocks.5.conv1.conv.weight, backbone.stage2.1.blocks.5.conv1.norm.weight, backbone.stage2.1.blocks.5.conv1.norm.bias, backbone.stage2.1.blocks.5.conv1.norm.running_mean, backbone.stage2.1.blocks.5.conv1.norm.running_var, backbone.stage2.1.blocks.5.conv2.conv.weight, backbone.stage2.1.blocks.5.conv2.norm.weight, backbone.stage2.1.blocks.5.conv2.norm.bias, backbone.stage2.1.blocks.5.conv2.norm.running_mean, backbone.stage2.1.blocks.5.conv2.norm.running_var, backbone.stage3.0.conv.conv.weight, backbone.stage3.0.conv.norm.weight, backbone.stage3.0.conv.norm.bias, backbone.stage3.0.conv.norm.running_mean, backbone.stage3.0.conv.norm.running_var, backbone.stage3.1.main_conv.norm.weight, backbone.stage3.1.main_conv.norm.bias, backbone.stage3.1.main_conv.norm.running_mean, backbone.stage3.1.main_conv.norm.running_var, backbone.stage3.1.short_conv.norm.weight, backbone.stage3.1.short_conv.norm.bias, backbone.stage3.1.short_conv.norm.running_mean, backbone.stage3.1.short_conv.norm.running_var, backbone.stage3.1.final_conv.norm.weight, backbone.stage3.1.final_conv.norm.bias, backbone.stage3.1.final_conv.norm.running_mean, backbone.stage3.1.final_conv.norm.running_var, backbone.stage3.1.blocks.0.conv1.norm.weight, backbone.stage3.1.blocks.0.conv1.norm.bias, backbone.stage3.1.blocks.0.conv1.norm.running_mean, backbone.stage3.1.blocks.0.conv1.norm.running_var, backbone.stage3.1.blocks.0.conv2.norm.weight, backbone.stage3.1.blocks.0.conv2.norm.bias, backbone.stage3.1.blocks.0.conv2.norm.running_mean, backbone.stage3.1.blocks.0.conv2.norm.running_var, backbone.stage3.1.blocks.1.conv1.norm.weight, backbone.stage3.1.blocks.1.conv1.norm.bias, backbone.stage3.1.blocks.1.conv1.norm.running_mean, backbone.stage3.1.blocks.1.conv1.norm.running_var, backbone.stage3.1.blocks.1.conv2.norm.weight, backbone.stage3.1.blocks.1.conv2.norm.bias, backbone.stage3.1.blocks.1.conv2.norm.running_mean, backbone.stage3.1.blocks.1.conv2.norm.running_var, backbone.stage3.1.blocks.2.conv1.norm.weight, backbone.stage3.1.blocks.2.conv1.norm.bias, backbone.stage3.1.blocks.2.conv1.norm.running_mean, backbone.stage3.1.blocks.2.conv1.norm.running_var, backbone.stage3.1.blocks.2.conv2.norm.weight, backbone.stage3.1.blocks.2.conv2.norm.bias, backbone.stage3.1.blocks.2.conv2.norm.running_mean, backbone.stage3.1.blocks.2.conv2.norm.running_var, backbone.stage3.1.blocks.3.conv1.conv.weight, backbone.stage3.1.blocks.3.conv1.norm.weight, backbone.stage3.1.blocks.3.conv1.norm.bias, backbone.stage3.1.blocks.3.conv1.norm.running_mean, backbone.stage3.1.blocks.3.conv1.norm.running_var, backbone.stage3.1.blocks.3.conv2.conv.weight, backbone.stage3.1.blocks.3.conv2.norm.weight, backbone.stage3.1.blocks.3.conv2.norm.bias, backbone.stage3.1.blocks.3.conv2.norm.running_mean, backbone.stage3.1.blocks.3.conv2.norm.running_var, backbone.stage3.1.blocks.4.conv1.conv.weight, backbone.stage3.1.blocks.4.conv1.norm.weight, backbone.stage3.1.blocks.4.conv1.norm.bias, backbone.stage3.1.blocks.4.conv1.norm.running_mean, backbone.stage3.1.blocks.4.conv1.norm.running_var, backbone.stage3.1.blocks.4.conv2.conv.weight, backbone.stage3.1.blocks.4.conv2.norm.weight, backbone.stage3.1.blocks.4.conv2.norm.bias, backbone.stage3.1.blocks.4.conv2.norm.running_mean, backbone.stage3.1.blocks.4.conv2.norm.running_var, backbone.stage3.1.blocks.5.conv1.conv.weight, backbone.stage3.1.blocks.5.conv1.norm.weight, backbone.stage3.1.blocks.5.conv1.norm.bias, backbone.stage3.1.blocks.5.conv1.norm.running_mean, backbone.stage3.1.blocks.5.conv1.norm.running_var, backbone.stage3.1.blocks.5.conv2.conv.weight, backbone.stage3.1.blocks.5.conv2.norm.weight, backbone.stage3.1.blocks.5.conv2.norm.bias, backbone.stage3.1.blocks.5.conv2.norm.running_mean, backbone.stage3.1.blocks.5.conv2.norm.running_var, backbone.stage3.1.blocks.6.conv1.conv.weight, backbone.stage3.1.blocks.6.conv1.norm.weight, backbone.stage3.1.blocks.6.conv1.norm.bias, backbone.stage3.1.blocks.6.conv1.norm.running_mean, backbone.stage3.1.blocks.6.conv1.norm.running_var, backbone.stage3.1.blocks.6.conv2.conv.weight, backbone.stage3.1.blocks.6.conv2.norm.weight, backbone.stage3.1.blocks.6.conv2.norm.bias, backbone.stage3.1.blocks.6.conv2.norm.running_mean, backbone.stage3.1.blocks.6.conv2.norm.running_var, backbone.stage3.1.blocks.7.conv1.conv.weight, backbone.stage3.1.blocks.7.conv1.norm.weight, backbone.stage3.1.blocks.7.conv1.norm.bias, backbone.stage3.1.blocks.7.conv1.norm.running_mean, backbone.stage3.1.blocks.7.conv1.norm.running_var, backbone.stage3.1.blocks.7.conv2.conv.weight, backbone.stage3.1.blocks.7.conv2.norm.weight, backbone.stage3.1.blocks.7.conv2.norm.bias, backbone.stage3.1.blocks.7.conv2.norm.running_mean, backbone.stage3.1.blocks.7.conv2.norm.running_var, backbone.stage3.1.blocks.8.conv1.conv.weight, backbone.stage3.1.blocks.8.conv1.norm.weight, backbone.stage3.1.blocks.8.conv1.norm.bias, backbone.stage3.1.blocks.8.conv1.norm.running_mean, backbone.stage3.1.blocks.8.conv1.norm.running_var, backbone.stage3.1.blocks.8.conv2.conv.weight, backbone.stage3.1.blocks.8.conv2.norm.weight, backbone.stage3.1.blocks.8.conv2.norm.bias, backbone.stage3.1.blocks.8.conv2.norm.running_mean, backbone.stage3.1.blocks.8.conv2.norm.running_var, backbone.stage4.0.conv.conv.weight, backbone.stage4.0.conv.norm.weight, backbone.stage4.0.conv.norm.bias, backbone.stage4.0.conv.norm.running_mean, backbone.stage4.0.conv.norm.running_var, backbone.stage4.1.main_conv.norm.weight, backbone.stage4.1.main_conv.norm.bias, backbone.stage4.1.main_conv.norm.running_mean, backbone.stage4.1.main_conv.norm.running_var, backbone.stage4.1.short_conv.norm.weight, backbone.stage4.1.short_conv.norm.bias, backbone.stage4.1.short_conv.norm.running_mean, backbone.stage4.1.short_conv.norm.running_var, backbone.stage4.1.final_conv.norm.weight, backbone.stage4.1.final_conv.norm.bias, backbone.stage4.1.final_conv.norm.running_mean, backbone.stage4.1.final_conv.norm.running_var, backbone.stage4.1.blocks.0.conv1.norm.weight, backbone.stage4.1.blocks.0.conv1.norm.bias, backbone.stage4.1.blocks.0.conv1.norm.running_mean, backbone.stage4.1.blocks.0.conv1.norm.running_var, backbone.stage4.1.blocks.0.conv2.norm.weight, backbone.stage4.1.blocks.0.conv2.norm.bias, backbone.stage4.1.blocks.0.conv2.norm.running_mean, backbone.stage4.1.blocks.0.conv2.norm.running_var, backbone.stage4.1.blocks.1.conv1.conv.weight, backbone.stage4.1.blocks.1.conv1.norm.weight, backbone.stage4.1.blocks.1.conv1.norm.bias, backbone.stage4.1.blocks.1.conv1.norm.running_mean, backbone.stage4.1.blocks.1.conv1.norm.running_var, backbone.stage4.1.blocks.1.conv2.conv.weight, backbone.stage4.1.blocks.1.conv2.norm.weight, backbone.stage4.1.blocks.1.conv2.norm.bias, backbone.stage4.1.blocks.1.conv2.norm.running_mean, backbone.stage4.1.blocks.1.conv2.norm.running_var, backbone.stage4.1.blocks.2.conv1.conv.weight, backbone.stage4.1.blocks.2.conv1.norm.weight, backbone.stage4.1.blocks.2.conv1.norm.bias, backbone.stage4.1.blocks.2.conv1.norm.running_mean, backbone.stage4.1.blocks.2.conv1.norm.running_var, backbone.stage4.1.blocks.2.conv2.conv.weight, backbone.stage4.1.blocks.2.conv2.norm.weight, backbone.stage4.1.blocks.2.conv2.norm.bias, backbone.stage4.1.blocks.2.conv2.norm.running_mean, backbone.stage4.1.blocks.2.conv2.norm.running_var, backbone.stage4.2.conv1.conv.conv.weight, backbone.stage4.2.conv1.conv.norm.weight, backbone.stage4.2.conv1.conv.norm.bias, backbone.stage4.2.conv1.conv.norm.running_mean, backbone.stage4.2.conv1.conv.norm.running_var, backbone.stage4.2.conv2.conv.conv.weight, backbone.stage4.2.conv2.conv.norm.weight, backbone.stage4.2.conv2.conv.norm.bias, backbone.stage4.2.conv2.conv.norm.running_mean, backbone.stage4.2.conv2.conv.norm.running_var, neck.reduce_layers.2.conv.conv.weight, neck.reduce_layers.2.conv.norm.weight, neck.reduce_layers.2.conv.norm.bias, neck.reduce_layers.2.conv.norm.running_mean, neck.reduce_layers.2.conv.norm.running_var, neck.top_down_layers.0.0.main_conv.norm.weight, neck.top_down_layers.0.0.main_conv.norm.bias, neck.top_down_layers.0.0.main_conv.norm.running_mean, neck.top_down_layers.0.0.main_conv.norm.running_var, neck.top_down_layers.0.0.short_conv.norm.weight, neck.top_down_layers.0.0.short_conv.norm.bias, neck.top_down_layers.0.0.short_conv.norm.running_mean, neck.top_down_layers.0.0.short_conv.norm.running_var, neck.top_down_layers.0.0.final_conv.norm.weight, neck.top_down_layers.0.0.final_conv.norm.bias, neck.top_down_layers.0.0.final_conv.norm.running_mean, neck.top_down_layers.0.0.final_conv.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv1.norm.weight, neck.top_down_layers.0.0.blocks.0.conv1.norm.bias, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv1.norm.running_var, neck.top_down_layers.0.0.blocks.0.conv2.norm.weight, neck.top_down_layers.0.0.blocks.0.conv2.norm.bias, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_mean, neck.top_down_layers.0.0.blocks.0.conv2.norm.running_var, neck.top_down_layers.0.1.conv.conv.weight, neck.top_down_layers.0.1.conv.norm.weight, neck.top_down_layers.0.1.conv.norm.bias, neck.top_down_layers.0.1.conv.norm.running_mean, neck.top_down_layers.0.1.conv.norm.running_var, neck.top_down_layers.1.main_conv.norm.weight, neck.top_down_layers.1.main_conv.norm.bias, neck.top_down_layers.1.main_conv.norm.running_mean, neck.top_down_layers.1.main_conv.norm.running_var, neck.top_down_layers.1.short_conv.norm.weight, neck.top_down_layers.1.short_conv.norm.bias, neck.top_down_layers.1.short_conv.norm.running_mean, neck.top_down_layers.1.short_conv.norm.running_var, neck.top_down_layers.1.final_conv.norm.weight, neck.top_down_layers.1.final_conv.norm.bias, neck.top_down_layers.1.final_conv.norm.running_mean, neck.top_down_layers.1.final_conv.norm.running_var, neck.top_down_layers.1.blocks.0.conv1.norm.weight, neck.top_down_layers.1.blocks.0.conv1.norm.bias, neck.top_down_layers.1.blocks.0.conv1.norm.running_mean, neck.top_down_layers.1.blocks.0.conv1.norm.running_var, neck.top_down_layers.1.blocks.0.conv2.norm.weight, neck.top_down_layers.1.blocks.0.conv2.norm.bias, neck.top_down_layers.1.blocks.0.conv2.norm.running_mean, neck.top_down_layers.1.blocks.0.conv2.norm.running_var, neck.downsample_layers.0.conv.conv.weight, neck.downsample_layers.0.conv.norm.weight, neck.downsample_layers.0.conv.norm.bias, neck.downsample_layers.0.conv.norm.running_mean, neck.downsample_layers.0.conv.norm.running_var, neck.downsample_layers.1.conv.conv.weight, neck.downsample_layers.1.conv.norm.weight, neck.downsample_layers.1.conv.norm.bias, neck.downsample_layers.1.conv.norm.running_mean, neck.downsample_layers.1.conv.norm.running_var, neck.bottom_up_layers.0.main_conv.norm.weight, neck.bottom_up_layers.0.main_conv.norm.bias, neck.bottom_up_layers.0.main_conv.norm.running_mean, neck.bottom_up_layers.0.main_conv.norm.running_var, neck.bottom_up_layers.0.short_conv.norm.weight, neck.bottom_up_layers.0.short_conv.norm.bias, neck.bottom_up_layers.0.short_conv.norm.running_mean, neck.bottom_up_layers.0.short_conv.norm.running_var, neck.bottom_up_layers.0.final_conv.norm.weight, neck.bottom_up_layers.0.final_conv.norm.bias, neck.bottom_up_layers.0.final_conv.norm.running_mean, neck.bottom_up_layers.0.final_conv.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv1.norm.weight, neck.bottom_up_layers.0.blocks.0.conv1.norm.bias, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.0.blocks.0.conv2.norm.weight, neck.bottom_up_layers.0.blocks.0.conv2.norm.bias, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.0.blocks.0.conv2.norm.running_var, neck.bottom_up_layers.1.main_conv.norm.weight, neck.bottom_up_layers.1.main_conv.norm.bias, neck.bottom_up_layers.1.main_conv.norm.running_mean, neck.bottom_up_layers.1.main_conv.norm.running_var, neck.bottom_up_layers.1.short_conv.norm.weight, neck.bottom_up_layers.1.short_conv.norm.bias, neck.bottom_up_layers.1.short_conv.norm.running_mean, neck.bottom_up_layers.1.short_conv.norm.running_var, neck.bottom_up_layers.1.final_conv.norm.weight, neck.bottom_up_layers.1.final_conv.norm.bias, neck.bottom_up_layers.1.final_conv.norm.running_mean, neck.bottom_up_layers.1.final_conv.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv1.norm.weight, neck.bottom_up_layers.1.blocks.0.conv1.norm.bias, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv1.norm.running_var, neck.bottom_up_layers.1.blocks.0.conv2.norm.weight, neck.bottom_up_layers.1.blocks.0.conv2.norm.bias, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_mean, neck.bottom_up_layers.1.blocks.0.conv2.norm.running_var\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     1/100     1.9229     0.0      0.2737    1.6492   1:25:42  : 100%|█████████| 247/247 [00:49<00:00,  4.95it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     2/100     1.4384     0.0      0.2129    1.2254   1:23:16  : 100%|█████████| 247/247 [00:49<00:00,  4.98it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     3/100     1.2048     0.0      0.1986    1.0061   1:21:33  : 100%|█████████| 247/247 [00:49<00:00,  5.04it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     4/100     1.1245     0.0      0.1914    0.9331   1:20:23  : 100%|█████████| 247/247 [00:49<00:00,  5.02it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     5/100     1.0699     0.0      0.1877    0.8822   1:19:44  : 100%|█████████| 247/247 [00:50<00:00,  4.90it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time      eta    \n",
            "   val      5/100     0.0611    0.2021   0:00:00  : 100%|███████████████████████████████| 22/22 [00:02<00:00, 10.18it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.882\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.319\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.427\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.472\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.541\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.577\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.583\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     6/100     1.0174     0.0      0.1816    0.8358   1:18:42  : 100%|█████████| 247/247 [00:49<00:00,  5.02it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     7/100     0.9742     0.0      0.1774    0.7968   1:17:49  : 100%|█████████| 247/247 [00:49<00:00,  4.98it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     8/100     0.9602     0.0      0.1769    0.7833   1:18:18  : 100%|█████████| 247/247 [00:56<00:00,  4.35it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     9/100     0.9323     0.0      0.1733    0.7591   1:19:55  : 100%|█████████| 247/247 [01:05<00:00,  3.79it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     10/100    0.9106     0.0      0.1708    0.7398   1:20:43  : 100%|█████████| 247/247 [01:03<00:00,  3.90it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      10/100    0.0232    0.1391     0.42     0.882     0.319      -1.0     0.034     0.427    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.50s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.19s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.961\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.733\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.619\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.656\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     11/100    0.9043     0.0      0.1702    0.7341   1:21:12  : 100%|█████████| 247/247 [01:03<00:00,  3.90it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     12/100    0.8806     0.0      0.1697    0.7108   1:20:56  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     13/100    0.8725     0.0      0.1696    0.7029   1:20:52  : 100%|█████████| 247/247 [01:02<00:00,  3.96it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     14/100    0.8758     0.0      0.1704    0.7053   1:20:24  : 100%|█████████| 247/247 [00:59<00:00,  4.13it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     15/100    0.857      0.0      0.1683    0.6887   1:20:09  : 100%|█████████| 247/247 [01:02<00:00,  3.93it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      15/100    0.0152    0.1322    0.614     0.961     0.733      -1.0     0.179     0.619    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.43s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.99s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.974\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.806\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.682\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.705\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.711\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.716\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     16/100    0.8394     0.0      0.1626    0.6768   1:19:50  : 100%|█████████| 247/247 [01:03<00:00,  3.89it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     17/100    0.8277     0.0      0.1628    0.6649   1:19:42  : 100%|█████████| 247/247 [01:06<00:00,  3.71it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     18/100    0.826      0.0      0.1615    0.6645   1:19:05  : 100%|█████████| 247/247 [01:01<00:00,  4.01it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     19/100    0.8313     0.0      0.1641    0.6672   1:18:18  : 100%|█████████| 247/247 [01:00<00:00,  4.12it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     20/100    0.8098     0.0      0.1626    0.6472   1:17:40  : 100%|█████████| 247/247 [01:02<00:00,  3.94it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      20/100    0.0137    0.131     0.635     0.974     0.806      -1.0     0.157      0.64    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.972\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.821\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.144\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.728\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     21/100    0.8005     0.0      0.1602    0.6403   1:16:58  : 100%|█████████| 247/247 [01:01<00:00,  4.00it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     22/100    0.8075     0.0      0.1601    0.6473   1:16:12  : 100%|█████████| 247/247 [01:01<00:00,  4.01it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     23/100     0.79      0.0      0.1601    0.6299   1:15:21  : 100%|█████████| 247/247 [01:00<00:00,  4.09it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     24/100    0.8023     0.0      0.1592    0.6431   1:14:33  : 100%|█████████| 247/247 [01:01<00:00,  3.99it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     25/100    0.7885     0.0      0.1577    0.6308   1:13:35  : 100%|█████████| 247/247 [00:58<00:00,  4.22it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      25/100    0.0152    0.1373    0.667     0.972     0.821      -1.0     0.144     0.673    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.674\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.979\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.876\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.145\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.721\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.741\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.746\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     26/100    0.7846     0.0      0.1597    0.6249   1:12:37  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     27/100    0.8082     0.0      0.1626    0.6456   1:11:42  : 100%|█████████| 247/247 [00:59<00:00,  4.14it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     28/100    0.7787     0.0      0.1601    0.6186   1:10:47  : 100%|█████████| 247/247 [01:00<00:00,  4.11it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     29/100    0.753      0.0      0.1561    0.5969   1:09:52  : 100%|█████████| 247/247 [01:00<00:00,  4.11it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     30/100    0.765      0.0      0.1563    0.6087   1:08:55  : 100%|█████████| 247/247 [00:59<00:00,  4.16it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      30/100    0.0167    0.1655    0.674     0.979     0.876      -1.0     0.145      0.68    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.05s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.710\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.979\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.889\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.739\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.752\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.763\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     31/100    0.7569     0.0      0.1558    0.6011   1:07:55  : 100%|█████████| 247/247 [00:58<00:00,  4.24it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     32/100    0.7397     0.0      0.1524    0.5873   1:07:02  : 100%|█████████| 247/247 [01:01<00:00,  4.02it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     33/100    0.7437     0.0      0.1526    0.5911   1:06:03  : 100%|█████████| 247/247 [00:58<00:00,  4.19it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     34/100    0.7395     0.0      0.1538    0.5856   1:05:06  : 100%|█████████| 247/247 [00:59<00:00,  4.16it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     35/100    0.7374     0.0      0.1516    0.5858   1:04:07  : 100%|█████████| 247/247 [00:58<00:00,  4.19it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      35/100    0.0191    0.1808     0.71     0.979     0.889      -1.0     0.119     0.715    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.36s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.08s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.21s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.727\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.975\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.898\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.733\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.776\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.778\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.784\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     36/100    0.7336     0.0      0.1514    0.5822   1:03:13  : 100%|█████████| 247/247 [01:01<00:00,  4.02it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     37/100    0.7281     0.0      0.1511    0.5769   1:02:15  : 100%|█████████| 247/247 [00:59<00:00,  4.16it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     38/100    0.7271     0.0      0.1514    0.5757   1:01:19  : 100%|█████████| 247/247 [01:00<00:00,  4.07it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     39/100    0.7292     0.0      0.1535    0.5758   1:00:19  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     40/100    0.7176     0.0      0.1494    0.5683   0:59:24  : 100%|█████████| 247/247 [01:01<00:00,  4.00it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      40/100    0.0168    0.1535    0.727     0.975     0.898      -1.0      0.2      0.733    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.877\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.778\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     41/100    0.7466     0.0      0.1527    0.5939   0:58:27  : 100%|█████████| 247/247 [01:00<00:00,  4.08it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     42/100    0.7338     0.0      0.1538     0.58    0:57:27  : 100%|█████████| 247/247 [00:58<00:00,  4.23it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     43/100     0.72      0.0      0.1512    0.5689   0:56:29  : 100%|█████████| 247/247 [00:59<00:00,  4.12it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     44/100    0.7589     0.0      0.1559    0.603    0:55:30  : 100%|█████████| 247/247 [00:59<00:00,  4.12it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     45/100    0.7458     0.0      0.1546    0.5912   0:54:31  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      45/100    0.0136    0.1287    0.723     0.976     0.877      -1.0      0.15      0.73    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.888\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.150\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.731\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.772\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.773\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     46/100    0.7223     0.0      0.1526    0.5697   0:53:32  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     47/100    0.7021     0.0      0.1511    0.551    0:52:33  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     48/100    0.7003     0.0      0.1499    0.5503   0:51:35  : 100%|█████████| 247/247 [01:00<00:00,  4.08it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     49/100    0.6842     0.0      0.1453    0.5389   0:50:36  : 100%|█████████| 247/247 [00:59<00:00,  4.17it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     50/100    0.6869     0.0      0.145     0.5419   0:49:36  : 100%|█████████| 247/247 [00:58<00:00,  4.23it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      50/100    0.0174    0.1366    0.726     0.976     0.888      -1.0      0.15     0.731    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.745\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.982\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.910\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.784\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.794\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     51/100    0.6893     0.0      0.1457    0.5436   0:48:38  : 100%|█████████| 247/247 [01:00<00:00,  4.09it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     52/100    0.6882     0.0      0.1463    0.5419   0:47:38  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     53/100    0.6906     0.0      0.1474    0.5432   0:46:38  : 100%|█████████| 247/247 [00:58<00:00,  4.24it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     54/100    0.6894     0.0      0.1479    0.5415   0:45:39  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     55/100    0.6915     0.0      0.1472    0.5443   0:44:39  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      55/100    0.0182    0.1401    0.745     0.982      0.91      -1.0     0.265      0.75    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.06s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.753\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.983\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.908\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.239\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.758\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.791\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.807\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     56/100    0.6839     0.0      0.1461    0.5379   0:43:39  : 100%|█████████| 247/247 [00:58<00:00,  4.23it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     57/100    0.6747     0.0      0.1447     0.53    0:42:40  : 100%|█████████| 247/247 [00:59<00:00,  4.14it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     58/100    0.6654     0.0      0.1442    0.5212   0:41:40  : 100%|█████████| 247/247 [00:58<00:00,  4.22it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     59/100    0.6775     0.0      0.147     0.5305   0:40:42  : 100%|█████████| 247/247 [01:00<00:00,  4.06it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     60/100    0.6614     0.0      0.143     0.5184   0:39:42  : 100%|█████████| 247/247 [00:58<00:00,  4.25it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      60/100    0.0147    0.1352    0.753     0.983     0.908      -1.0     0.239     0.758    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.27s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.754\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.910\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.760\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.790\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.796\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.799\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     61/100    0.6674     0.0      0.144     0.5233   0:38:42  : 100%|█████████| 247/247 [00:58<00:00,  4.24it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     62/100    0.6624     0.0      0.1428    0.5196   0:37:43  : 100%|█████████| 247/247 [01:00<00:00,  4.09it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     63/100    0.6596     0.0      0.1441    0.5155   0:36:44  : 100%|█████████| 247/247 [01:00<00:00,  4.10it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     64/100    0.6513     0.0      0.1429    0.5084   0:35:44  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     65/100    0.6632     0.0      0.1439    0.5193   0:34:45  : 100%|█████████| 247/247 [00:59<00:00,  4.15it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      65/100    0.0135    0.1284    0.754     0.978      0.91      -1.0     0.299      0.76    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.96s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.757\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.914\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.792\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     66/100    0.6559     0.0      0.1422    0.5137   0:33:46  : 100%|█████████| 247/247 [01:01<00:00,  4.03it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     67/100    0.6459     0.0      0.1418    0.504    0:32:49  : 100%|█████████| 247/247 [01:03<00:00,  3.92it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     68/100    0.6387     0.0      0.1407    0.4979   0:31:49  : 100%|█████████| 247/247 [00:59<00:00,  4.14it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     69/100    0.6333     0.0      0.1405    0.4929   0:30:50  : 100%|█████████| 247/247 [01:00<00:00,  4.08it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     70/100    0.6426     0.0      0.1411    0.5015   0:29:50  : 100%|█████████| 247/247 [00:58<00:00,  4.19it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      70/100    0.0149    0.132     0.757     0.978     0.914      -1.0     0.332     0.762    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.764\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.794\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     71/100    0.625      0.0      0.1402    0.4848   0:28:51  : 100%|█████████| 247/247 [00:58<00:00,  4.19it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     72/100    0.6321     0.0      0.1412    0.491    0:27:51  : 100%|█████████| 247/247 [00:59<00:00,  4.13it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     73/100     0.63      0.0      0.1415    0.4885   0:26:51  : 100%|█████████| 247/247 [00:58<00:00,  4.24it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     74/100    0.6256     0.0      0.1399    0.4857   0:25:52  : 100%|█████████| 247/247 [01:01<00:00,  4.01it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     75/100    0.6346     0.0      0.1416    0.493    0:24:52  : 100%|█████████| 247/247 [00:58<00:00,  4.23it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      75/100    0.0159    0.1424    0.758     0.978     0.919      -1.0     0.332     0.764    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.44s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.72s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.32s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.756\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.762\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.794\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.805\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     76/100    0.626      0.0      0.1398    0.4862   0:23:52  : 100%|█████████| 247/247 [00:58<00:00,  4.20it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     77/100    0.6236     0.0      0.1394    0.4842   0:22:53  : 100%|█████████| 247/247 [00:59<00:00,  4.17it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     78/100    0.6084     0.0      0.1356    0.4728   0:21:53  : 100%|█████████| 247/247 [01:00<00:00,  4.10it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     79/100    0.6121     0.0      0.1374    0.4748   0:20:54  : 100%|█████████| 247/247 [01:00<00:00,  4.11it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     80/100    0.6147     0.0      0.1393    0.4754   0:19:54  : 100%|█████████| 247/247 [00:59<00:00,  4.12it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      80/100    0.0154    0.1391    0.756     0.978     0.917      -1.0     0.332     0.762    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.91s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.22s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.758\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.917\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.797\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     81/100    0.6096     0.0      0.1385    0.4711   0:18:55  : 100%|█████████| 247/247 [01:00<00:00,  4.08it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     82/100    0.6049     0.0      0.1373    0.4676   0:17:56  : 100%|█████████| 247/247 [01:02<00:00,  3.98it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     83/100    0.5997     0.0      0.1334    0.4663   0:16:56  : 100%|█████████| 247/247 [00:59<00:00,  4.12it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     84/100    0.607      0.0      0.1375    0.4695   0:15:57  : 100%|█████████| 247/247 [01:01<00:00,  4.05it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     85/100    0.5964     0.0      0.1358    0.4606   0:14:57  : 100%|█████████| 247/247 [01:00<00:00,  4.06it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      85/100    0.015     0.1267    0.758     0.978     0.917      -1.0     0.332     0.765    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.50s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.15s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.18s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.762\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.915\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.800\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.807\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     86/100    0.6012     0.0      0.1366    0.4646   0:13:57  : 100%|█████████| 247/247 [00:59<00:00,  4.13it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     87/100    0.5985     0.0      0.1345    0.4641   0:12:58  : 100%|█████████| 247/247 [01:00<00:00,  4.06it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     88/100    0.5985     0.0      0.136     0.4625   0:11:58  : 100%|█████████| 247/247 [00:59<00:00,  4.12it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     89/100    0.5982     0.0      0.1365    0.4617   0:10:58  : 100%|█████████| 247/247 [01:02<00:00,  3.96it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     90/100    0.592      0.0      0.1349    0.4571   0:09:58  : 100%|█████████| 247/247 [00:58<00:00,  4.21it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      90/100    0.0177    0.1467    0.762     0.978     0.915      -1.0     0.332     0.767    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.96s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.763\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.769\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.801\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.809\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.809\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.814\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     91/100    0.5939     0.0      0.1355    0.4584   0:08:59  : 100%|█████████| 247/247 [01:01<00:00,  4.03it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     92/100    0.5859     0.0      0.134     0.4519   0:07:59  : 100%|█████████| 247/247 [01:02<00:00,  3.98it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     93/100    0.5841     0.0      0.1352    0.4488   0:06:59  : 100%|█████████| 247/247 [01:01<00:00,  4.00it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     94/100    0.5848     0.0      0.133     0.4518   0:05:59  : 100%|█████████| 247/247 [00:59<00:00,  4.18it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     95/100    0.5784     0.0      0.1342    0.4442   0:04:59  : 100%|█████████| 247/247 [01:00<00:00,  4.06it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val      95/100    0.0179    0.1533    0.763     0.978      0.92      -1.0     0.332     0.769    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.920\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.771\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.812\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.817\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     96/100    0.574      0.0      0.1331    0.4409   0:04:00  : 100%|█████████| 247/247 [01:02<00:00,  3.94it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     97/100    0.5793     0.0      0.1334    0.446    0:03:00  : 100%|█████████| 247/247 [01:00<00:00,  4.11it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     98/100    0.5726     0.0      0.1328    0.4398   0:02:00  : 100%|█████████| 247/247 [01:00<00:00,  4.08it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train     99/100    0.5704     0.0      0.1321    0.4382   0:01:00  : 100%|█████████| 247/247 [01:00<00:00,  4.11it/s]\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "   Mode     Epoch      loss    loss_cls  loss_obj loss_bbox    eta    \n",
            "  train    100/100    0.5613     0.0      0.1301    0.4312   0:00:00  : 100%|█████████| 247/247 [01:01<00:00,  4.02it/s]\n",
            "\n",
            "\n",
            "   Mode     Epoch   data_time    time   coco/bbox_mAPcoco/bbox_mAP_50coco/bbox_mAP_75coco/bbox_mAP_scoco/bbox_mAP_mcoco/bbox_mAP_l   eta    \n",
            "   val     100/100    0.0169    0.1393    0.765     0.978      0.92      -1.0     0.332     0.771    0:00:00  : 100%|█| \n",
            "Loading and preparing results...\n",
            "DONE (t=0.42s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.75s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.31s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.768\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.809\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.814\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX2CKmp15zfV"
      },
      "source": [
        "## 📦Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yBS2mhjA5zfV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "with open('BokChoy_Disease_Swift-YOLO_96/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2HLYBod5zfV",
        "outputId": "ce211137-9709-4acb-fc0b-cb3aa210d165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using automatically generated input type (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): image\n",
            "Using automatically generated input shape (from config 'swift_yolo_tiny_1xb16_300e_coco.py'): [1, 3, 96, 96]\n",
            "08/04 18:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1404593593\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1404593593\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 18:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_181936'}\n",
            "2025-08-04 18:19:38.846725: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754331578.870044   29202 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754331578.877358   29202 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 18:19:38.901438: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 18:19:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 18:19:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "WARNING (tinynn.graph.tracer) Constant generation is experimental and may yield error\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "100%|███████████| 100/100 [00:10<00:00,  9.77it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:1209: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n",
            "/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/yolodetector_q.py:1043: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_0_f = torch.as_tensor(8, dtype=torch.float32, device=device_1_f)\n",
            "/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/yolodetector_q.py:1114: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_1_f = torch.as_tensor(16, dtype=torch.float32, device=device_3_f)\n",
            "/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/yolodetector_q.py:1185: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  as_tensor_2_f = torch.as_tensor(32, dtype=torch.float32, device=device_5_f)\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1616 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1625 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1662 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1670 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1706 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) 1714 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_int8.tflite\n",
            "Warning: No configuration file specified. Using a default of ['/usr/local/lib/python3.11/dist-packages/ethosu/config_files/Arm/vela.ini']. Compilation may be invalid or non-optimal.\n",
            "Warning: No system configuration specified. Using a default of Ethos_U55_High_End_Embedded. Compilation may be invalid or non-optimal.\n",
            "Warning: No memory mode specified. Using a default of Shared_Sram. Compilation may be invalid or non-optimal.\n",
            "Warning: TRANSPOSE 'contiguous_0_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 144] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2854' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 12, 12, 18] and permutation is: [0 3 1 2]\n",
            "Info: PADV2 'input.37_transform_2' is a CPU only op\n",
            "Info: PADV2 'input.39_transform_2' is a CPU only op\n",
            "Info: PADV2 '2677_transform_2' is a CPU only op\n",
            "Warning: TRANSPOSE 'contiguous_1_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 36] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2859' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 6, 6, 18] and permutation is: [0 3 1 2]\n",
            "Warning: TRANSPOSE 'contiguous_2_f.1' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 6, 9] and permutation is: [0 1 3 2]\n",
            "Warning: TRANSPOSE '2864' is not supported on the NPU. Placing on CPU instead\n",
            " - The following shape/permutations are supported for transpose:\n",
            "        When ifm rank is 2: WxC -> CxW\n",
            "        When ifm rank is 3: HxWxC -> WxHxC, 1xWxC -> 1xCxW, Hx1xC -> Cx1xH\n",
            "        When ifm rank is 4: 1xHxWxC -> 1xWxHxC, 1x1xWxC -> 1x1xCxW, 1xHx1xC -> 1xCx1xW\n",
            "   Op has ifm_shape: [1, 3, 3, 18] and permutation is: [0 3 1 2]\n",
            "\n",
            "Network summary for epoch_100_int8\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration             Ethos_U55_High_End_Embedded\n",
            "Memory mode                               Shared_Sram\n",
            "Accelerator clock                                 500 MHz\n",
            "Design peak SRAM bandwidth                       3.73 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.47 GB/s\n",
            "\n",
            "Total SRAM used                                134.48 KiB\n",
            "Total Off-chip Flash used                     1134.70 KiB\n",
            "\n",
            "CPU operators = 9 (4.6%)\n",
            "NPU operators = 187 (95.4%)\n",
            "\n",
            "Average SRAM bandwidth                           0.82 GB/s\n",
            "Input   SRAM bandwidth                           0.94 MB/batch\n",
            "Weight  SRAM bandwidth                           2.60 MB/batch\n",
            "Output  SRAM bandwidth                           0.52 MB/batch\n",
            "Total   SRAM bandwidth                           4.11 MB/batch\n",
            "Total   SRAM bandwidth            per input      4.11 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.21 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.02 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 1.04 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 1.06 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      1.06 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                          33610770 MACs/batch\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_int8.tflite\n",
            "/content/ModelAssistant/sscma/models/heads/yolov5_head.py:125: TracerWarning: torch.as_tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  xy = (feat_xy * 2 - 0.5 + grid) * torch.as_tensor(\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx0.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) ny1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "WARNING (tinynn.converter.operators.torch.prim) nx1.1 is of type int64, which is unsupported in TFLite, trying to downcast to int32\n",
            "INFO (tinynn.converter.base) Generated model saved to /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.tflite\n",
            "Warning: No configuration file specified. Using a default of ['/usr/local/lib/python3.11/dist-packages/ethosu/config_files/Arm/vela.ini']. Compilation may be invalid or non-optimal.\n",
            "Warning: No system configuration specified. Using a default of Ethos_U55_High_End_Embedded. Compilation may be invalid or non-optimal.\n",
            "Warning: No memory mode specified. Using a default of Shared_Sram. Compilation may be invalid or non-optimal.\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '668_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: inputs.1, fuse_attr_319_reshape, 668_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '668_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform, 668_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '668_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1_te_transform_2, fuse_attr_320_reshape, 668_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '702_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1, fuse_attr_322_reshape, 702_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '737_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 702_te_transform_1, fuse_attr_323_reshape, 737_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_36'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 737_te_transform, fuse_attr_324_reshape, fuse_transform_36\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_38'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_36, 702_te_transform_1, fuse_transform_38\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '770_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_38, fuse_attr_325_reshape, 770_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_54'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 770_te_transform, fuse_attr_326_reshape, fuse_transform_54\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_56'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_54, fuse_transform_38, fuse_transform_56\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '803_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_56, fuse_attr_327_reshape, 803_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_57'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 803_te_transform, fuse_attr_328_reshape, fuse_transform_57\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_63'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_57, fuse_transform_56, fuse_transform_63\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_64'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 668_te_transform_1, fuse_attr_321_reshape, fuse_transform_64\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '821_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_64, 821_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '839_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 821_te_transform, fuse_attr_329_reshape, 839_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '839_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform, 839_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '839_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1_te_transform_2, fuse_attr_330_reshape, 839_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '873_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1, fuse_attr_332_reshape, 873_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '911_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 873_te_transform_1, fuse_attr_333_reshape, 911_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_84'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 911_te_transform, fuse_attr_334_reshape, fuse_transform_84\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_86'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_84, 873_te_transform_1, fuse_transform_86\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '944_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_86, fuse_attr_335_reshape, 944_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_95'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 944_te_transform, fuse_attr_336_reshape, fuse_transform_95\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_97'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_95, fuse_transform_86, fuse_transform_97\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '977_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_97, fuse_attr_337_reshape, 977_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_110'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 977_te_transform, fuse_attr_338_reshape, fuse_transform_110\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_112'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_110, fuse_transform_97, fuse_transform_112\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1010_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_112, fuse_attr_339_reshape, 1010_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_115'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1010_te_transform, fuse_attr_340_reshape, fuse_transform_115\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_117'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_115, fuse_transform_112, fuse_transform_117\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1043_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_117, fuse_attr_341_reshape, 1043_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_24'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1043_te_transform, fuse_attr_342_reshape, fuse_transform_24\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_26'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_24, fuse_transform_117, fuse_transform_26\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1076_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_26, fuse_attr_343_reshape, 1076_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_30'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1076_te_transform, fuse_attr_344_reshape, fuse_transform_30\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_27'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_30, fuse_transform_26, fuse_transform_27\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_28'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 839_te_transform_1, fuse_attr_331_reshape, fuse_transform_28\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1094_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_28, 1094_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1094_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform, fuse_attr_345_reshape, 1094_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1112_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform_1, 1112_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1112_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1_te_transform_2, fuse_attr_346_reshape, 1112_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1146_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1, fuse_attr_348_reshape, 1146_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1187_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1146_te_transform_1, fuse_attr_349_reshape, 1187_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_45'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1187_te_transform, fuse_attr_350_reshape, fuse_transform_45\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_47'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_45, 1146_te_transform_1, fuse_transform_47\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1220_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_47, fuse_attr_351_reshape, 1220_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_60'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1220_te_transform, fuse_attr_352_reshape, fuse_transform_60\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_62'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_60, fuse_transform_47, fuse_transform_62\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1253_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_62, fuse_attr_353_reshape, 1253_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_75'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1253_te_transform, fuse_attr_354_reshape, fuse_transform_75\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_77'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_75, fuse_transform_62, fuse_transform_77\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1286_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_77, fuse_attr_355_reshape, 1286_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_78'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1286_te_transform, fuse_attr_356_reshape, fuse_transform_78\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_80'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_78, fuse_transform_77, fuse_transform_80\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1319_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_80, fuse_attr_357_reshape, 1319_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_92'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1319_te_transform, fuse_attr_358_reshape, fuse_transform_92\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_94'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_92, fuse_transform_80, fuse_transform_94\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1352_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_94, fuse_attr_359_reshape, 1352_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_98'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1352_te_transform, fuse_attr_360_reshape, fuse_transform_98\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_100'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_98, fuse_transform_94, fuse_transform_100\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1385_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_100, fuse_attr_361_reshape, 1385_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_104'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1385_te_transform, fuse_attr_362_reshape, fuse_transform_104\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_106'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_104, fuse_transform_100, fuse_transform_106\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1418_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_106, fuse_attr_363_reshape, 1418_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_123'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1418_te_transform, fuse_attr_364_reshape, fuse_transform_123\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_125'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_123, fuse_transform_106, fuse_transform_125\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1451_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_125, fuse_attr_365_reshape, 1451_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_21'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1451_te_transform, fuse_attr_366_reshape, fuse_transform_21\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_18'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_21, fuse_transform_125, fuse_transform_18\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_19'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1112_te_transform_1, fuse_attr_347_reshape, fuse_transform_19\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1469_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_19, 1469_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1469_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform, fuse_attr_367_reshape, 1469_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1488_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform_1, 1488_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1488_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1_te_transform_2, fuse_attr_368_reshape, 1488_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1522_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1, fuse_attr_370_reshape, 1522_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1557_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1522_te_transform_1, fuse_attr_371_reshape, 1557_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_39'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1557_te_transform, fuse_attr_372_reshape, fuse_transform_39\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_41'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_39, 1522_te_transform_1, fuse_transform_41\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1590_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_41, fuse_attr_373_reshape, 1590_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_48'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1590_te_transform, fuse_attr_374_reshape, fuse_transform_48\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_50'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_48, fuse_transform_41, fuse_transform_50\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1623_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_50, fuse_attr_375_reshape, 1623_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_69'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1623_te_transform, fuse_attr_376_reshape, fuse_transform_69\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD 'fuse_transform_66'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_69, fuse_transform_50, fuse_transform_66\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_67'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1488_te_transform_1, fuse_attr_369_reshape, fuse_transform_67\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1641_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_67, 1641_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1660_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1641_te_transform, fuse_attr_377_reshape, 1660_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1660_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1660_te_transform, fuse_attr_378_reshape, 1660_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.39_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1660_te_transform_1, input.39_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'input.49_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MAX_POOL_2D 'fuse_transform_90'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.49_transform_1, fuse_transform_90\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1693_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: input.39_transform_1, input.49_transform_1, 1693_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1747_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1693_te_transform, fuse_attr_379_reshape, 1747_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1747_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform, fuse_attr_380_reshape, 1747_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_107'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform_1, fuse_transform_107\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_109'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1469_te_transform_1, fuse_transform_109\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1805_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_109, fuse_attr_382_reshape, 1805_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1820_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1805_te_transform, fuse_attr_383_reshape, 1820_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_120'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1820_te_transform, fuse_attr_384_reshape, fuse_transform_120\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_121'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_109, fuse_attr_381_reshape, fuse_transform_121\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1837_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_121, 1837_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1853_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1837_te_transform, fuse_attr_385_reshape, 1853_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1853_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform, fuse_attr_386_reshape, 1853_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESIZE_NEAREST_NEIGHBOR 'fuse_transform_33'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform_1, fuse_transform_33\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_35'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1094_te_transform_1, fuse_transform_35\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1909_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_35, fuse_attr_388_reshape, 1909_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1924_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1909_te_transform, fuse_attr_389_reshape, 1924_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_42'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1924_te_transform, fuse_attr_390_reshape, fuse_transform_42\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_43'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_35, fuse_attr_387_reshape, fuse_transform_43\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '1941_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_43, 1941_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '1941_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform, fuse_attr_391_reshape, 1941_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_113'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform_1, fuse_attr_404_reshape, fuse_transform_113\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_114'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_113, fuse_transform_114\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.9, pred_map0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '268:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_.1, 268:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2571'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:0, 2570, 2571\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2573'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2571, 2572, 2573\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '282'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2573, grid.1, 282\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 282, 2574, xy.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:1, 2576, wh.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh.1, wh.1, wh0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh0.1, grid_.1, wh1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 268:2, 2578, cls.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh1.1, cls.1, out.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '313'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out.1, 313\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '1957_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1941_te_transform_1, 1957_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_51'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1957_te_transform_1_te_transform_2, fuse_attr_392_reshape, fuse_transform_51\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_53'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1853_te_transform_1, fuse_transform_53\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2011_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_53, fuse_attr_394_reshape, 2011_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2026_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2011_te_transform, fuse_attr_395_reshape, 2026_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_72'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2026_te_transform, fuse_attr_396_reshape, fuse_transform_72\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_73'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_53, fuse_attr_393_reshape, fuse_transform_73\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2043_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_73, 2043_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2043_te_transform_1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform, fuse_attr_397_reshape, 2043_te_transform_1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_118'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform_1, fuse_attr_405_reshape, fuse_transform_118\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_119'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_118, fuse_transform_119\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map1.1, pred_map2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '407:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_0.1, 407:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2581'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:0, 2580, 2581\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2583'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2581, 2582, 2583\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '421'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2583, grid0.1, 421\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 421, 2584, xy0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh2.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:1, 2586, wh2.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh3.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh2.1, wh2.1, wh3.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh3.1, grid_0.1, wh4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 407:2, 2588, cls0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out0.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh4.1, cls0.1, out0.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '452'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out0.1, 452\n",
            "Warning: Unsupported TensorFlow Lite semantics for PAD '2059_te_transform_1_te_transform_2'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2043_te_transform_1, 2059_te_transform_1_te_transform_2\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_81'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2059_te_transform_1_te_transform_2, fuse_attr_398_reshape, fuse_transform_81\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'fuse_transform_83'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 1747_te_transform_1, fuse_transform_83\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2113_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_83, fuse_attr_400_reshape, 2113_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D '2128_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2113_te_transform, fuse_attr_401_reshape, 2128_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_101'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2128_te_transform, fuse_attr_402_reshape, fuse_transform_101\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_102'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_83, fuse_attr_399_reshape, fuse_transform_102\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '2145_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_102, 2145_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'pred_map.1_te_transform'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2145_te_transform, fuse_attr_403_reshape, pred_map.1_te_transform\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONV_2D 'fuse_transform_126'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map.1_te_transform, fuse_attr_406_reshape, fuse_transform_126\n",
            "Warning: Unsupported TensorFlow Lite semantics for LOGISTIC 'fuse_transform_127'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: fuse_transform_126, fuse_transform_127\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE 'pred_map4.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: pred_map3.1, pred_map4.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for SPLIT_V '546:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: feat_1.1, 546:0\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL '2591'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:0, 2590, 2591\n",
            "Warning: Unsupported TensorFlow Lite semantics for SUB '2593'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2591, 2592, 2593\n",
            "Warning: Unsupported TensorFlow Lite semantics for ADD '560'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 2593, grid1.1, 560\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'xy1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 560, 2594, xy1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh5.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:1, 2596, wh5.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh6.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh5.1, wh5.1, wh6.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'wh7.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh6.1, grid_1.1, wh7.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for MUL 'cls1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 546:2, 2598, cls1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION 'out1.1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: wh7.1, cls1.1, out1.1\n",
            "Warning: Unsupported TensorFlow Lite semantics for RESHAPE '593'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: out1.1, 593\n",
            "Warning: Unsupported TensorFlow Lite semantics for CONCATENATION '596'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: 452, 593, 596\n",
            "Warning: TRANSPOSE 'feat_.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map0.1' has data type: float32, Tensor 'feat_.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map.9' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_114' has data type: float32, Tensor 'pred_map.9' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_0.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map2.1' has data type: float32, Tensor 'feat_0.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_119' has data type: float32, Tensor 'pred_map1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'feat_1.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'pred_map4.1' has data type: float32, Tensor 'feat_1.1' has data type: float32\n",
            "Warning: TRANSPOSE 'pred_map3.1' is not supported on the NPU. Placing on CPU instead\n",
            " - Tensors must be of type: int16, int32, int8, uint8\n",
            "   Tensor 'fuse_transform_127' has data type: float32, Tensor 'pred_map3.1' has data type: float32\n",
            "\n",
            "Network summary for epoch_100_float32\n",
            "Accelerator configuration                Ethos_U55_64\n",
            "System configuration             Ethos_U55_High_End_Embedded\n",
            "Memory mode                               Shared_Sram\n",
            "Accelerator clock                                 500 MHz\n",
            "\n",
            "\n",
            "CPU operators = 179 (100.0%)\n",
            "NPU operators = 0 (0.0%)\n",
            "\n",
            "Neural network macs                                 0 MACs/batch\n",
            "\n",
            "TFLite: Successfully export model: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.tflite\n",
            "ONNX: Ignoring unsupported precision: int8\n",
            "Exported graph: graph(%input : Float(1, 3, 96, 96, strides=[27648, 9216, 96, 1], requires_grad=0, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.weight : Float(18, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.0.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.weight : Float(18, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.1.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.weight : Float(18, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=1, device=cpu),\n",
            "      %bbox_head.head_module.convs_pred.2.bias : Float(18, strides=[1], requires_grad=1, device=cpu),\n",
            "      %onnx::Conv_1102 : Float(16, 3, 6, 6, strides=[108, 36, 6, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1103 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1105 : Float(24, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1106 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1108 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1109 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1111 : Float(12, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1112 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1114 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1115 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1117 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1118 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1120 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1121 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1123 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1124 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1126 : Float(12, 12, 1, 1, strides=[12, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1127 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1129 : Float(12, 12, 3, 3, strides=[108, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1130 : Float(12, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1132 : Float(24, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1133 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1135 : Float(40, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1136 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1138 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1139 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1141 : Float(20, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1142 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1144 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1145 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1147 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1148 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1150 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1151 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1153 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1154 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1156 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1157 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1159 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1160 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1162 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1163 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1165 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1166 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1168 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1169 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1171 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1172 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1174 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1175 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1177 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1178 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1180 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1181 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1183 : Float(80, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1184 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1186 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1187 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1189 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1190 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1192 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1193 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1195 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1196 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1198 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1199 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1201 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1202 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1204 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1205 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1207 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1208 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1210 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1211 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1213 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1214 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1216 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1217 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1219 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1220 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1222 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1223 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1225 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1226 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1228 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1229 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1231 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1232 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1234 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1235 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1237 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1238 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1240 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1241 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1243 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1244 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1246 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1247 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1249 : Float(160, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1250 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1252 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1253 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1255 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1256 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1258 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1259 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1261 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1262 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1264 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1265 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1267 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1268 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1270 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1271 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1273 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1274 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1276 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1277 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1279 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1280 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1282 : Float(160, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1283 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1285 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1286 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1288 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1289 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1291 : Float(40, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1292 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1294 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1295 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1297 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1298 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1300 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1301 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1303 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1304 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1306 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1307 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1309 : Float(20, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1310 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1312 : Float(20, 20, 1, 1, strides=[20, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1313 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1315 : Float(20, 20, 3, 3, strides=[180, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1316 : Float(20, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1318 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1319 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1321 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1322 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1324 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1325 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1327 : Float(40, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1328 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1330 : Float(40, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1331 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1333 : Float(40, 40, 3, 3, strides=[360, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1334 : Float(40, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1336 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1337 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1339 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1340 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1342 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1343 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1345 : Float(80, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1346 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1348 : Float(80, 80, 1, 1, strides=[80, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1349 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1351 : Float(80, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1352 : Float(80, strides=[1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1354 : Float(160, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
            "      %onnx::Conv_1355 : Float(160, strides=[1], requires_grad=0, device=cpu)):\n",
            "  %/backbone/stem/conv/conv/Conv_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[6, 6], pads=[2, 2, 2, 2], strides=[2, 2], onnx_name=\"/backbone/stem/conv/conv/Conv\"](%input, %onnx::Conv_1102, %onnx::Conv_1103), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stem/conv/act/Relu_output_0 : Float(1, 16, 48, 48, strides=[36864, 2304, 48, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stem/conv/act/Relu\"](%/backbone/stem/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/sscma.models.base.conv_module.ConvModule::stem/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.0/conv/conv/Conv_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage1/stage1.0/conv/conv/Conv\"](%/backbone/stem/conv/act/Relu_output_0, %onnx::Conv_1105, %onnx::Conv_1106), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.0/conv/act/Relu_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.0/conv/act/Relu\"](%/backbone/stage1/stage1.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.base.conv_module.ConvModule::stage1.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/short_conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1108, %onnx::Conv_1109), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/short_conv/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/short_conv/act/Relu\"](%/backbone/stage1/stage1.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/main_conv/conv/Conv\"](%/backbone/stage1/stage1.0/conv/act/Relu_output_0, %onnx::Conv_1111, %onnx::Conv_1112), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/main_conv/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/main_conv/act/Relu\"](%/backbone/stage1/stage1.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/main_conv/act/Relu_output_0, %onnx::Conv_1114, %onnx::Conv_1115), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1117, %onnx::Conv_1118), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.0/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1120, %onnx::Conv_1121), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1123, %onnx::Conv_1124), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.1/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1126, %onnx::Conv_1127), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1129, %onnx::Conv_1130), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0 : Float(1, 12, 24, 24, strides=[6912, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage1/stage1.1/blocks/blocks.2/Add\"](%/backbone/stage1/stage1.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage1/stage1.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage1/stage1.1/Concat_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage1/stage1.1/Concat\"](%/backbone/stage1/stage1.1/blocks/blocks.2/Add_output_0, %/backbone/stage1/stage1.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage1/stage1.1/final_conv/conv/Conv\"](%/backbone/stage1/stage1.1/Concat_output_0, %onnx::Conv_1132, %onnx::Conv_1133), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage1/stage1.1/final_conv/act/Relu_output_0 : Float(1, 24, 24, 24, strides=[13824, 576, 24, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage1/stage1.1/final_conv/act/Relu\"](%/backbone/stage1/stage1.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage1/sscma.models.layers.csp_layer.CSPLayer::stage1.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.0/conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage2/stage2.0/conv/conv/Conv\"](%/backbone/stage1/stage1.1/final_conv/act/Relu_output_0, %onnx::Conv_1135, %onnx::Conv_1136), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.0/conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.0/conv/act/Relu\"](%/backbone/stage2/stage2.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.base.conv_module.ConvModule::stage2.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/short_conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1138, %onnx::Conv_1139), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/short_conv/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/short_conv/act/Relu\"](%/backbone/stage2/stage2.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/main_conv/conv/Conv\"](%/backbone/stage2/stage2.0/conv/act/Relu_output_0, %onnx::Conv_1141, %onnx::Conv_1142), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/main_conv/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/main_conv/act/Relu\"](%/backbone/stage2/stage2.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/main_conv/act/Relu_output_0, %onnx::Conv_1144, %onnx::Conv_1145), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1147, %onnx::Conv_1148), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.0/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1150, %onnx::Conv_1151), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1153, %onnx::Conv_1154), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.1/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1156, %onnx::Conv_1157), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1159, %onnx::Conv_1160), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.2/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1162, %onnx::Conv_1163), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv1/act/Relu_output_0, %onnx::Conv_1165, %onnx::Conv_1166), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.3/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.3/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1168, %onnx::Conv_1169), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv1/act/Relu_output_0, %onnx::Conv_1171, %onnx::Conv_1172), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.4/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.4/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1174, %onnx::Conv_1175), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv1/act/Relu_output_0, %onnx::Conv_1177, %onnx::Conv_1178), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage2/stage2.1/blocks/blocks.5/Add\"](%/backbone/stage2/stage2.1/blocks/blocks.5/conv2/act/Relu_output_0, %/backbone/stage2/stage2.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage2/stage2.1/Concat_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage2/stage2.1/Concat\"](%/backbone/stage2/stage2.1/blocks/blocks.5/Add_output_0, %/backbone/stage2/stage2.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage2/stage2.1/final_conv/conv/Conv\"](%/backbone/stage2/stage2.1/Concat_output_0, %onnx::Conv_1180, %onnx::Conv_1181), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage2/stage2.1/final_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage2/stage2.1/final_conv/act/Relu\"](%/backbone/stage2/stage2.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage2/sscma.models.layers.csp_layer.CSPLayer::stage2.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.0/conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage3/stage3.0/conv/conv/Conv\"](%/backbone/stage2/stage2.1/final_conv/act/Relu_output_0, %onnx::Conv_1183, %onnx::Conv_1184), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.0/conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.0/conv/act/Relu\"](%/backbone/stage3/stage3.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.base.conv_module.ConvModule::stage3.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/short_conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1186, %onnx::Conv_1187), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/short_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/short_conv/act/Relu\"](%/backbone/stage3/stage3.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/main_conv/conv/Conv\"](%/backbone/stage3/stage3.0/conv/act/Relu_output_0, %onnx::Conv_1189, %onnx::Conv_1190), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/main_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/main_conv/act/Relu\"](%/backbone/stage3/stage3.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/main_conv/act/Relu_output_0, %onnx::Conv_1192, %onnx::Conv_1193), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1195, %onnx::Conv_1196), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.0/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1198, %onnx::Conv_1199), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1201, %onnx::Conv_1202), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.1/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1204, %onnx::Conv_1205), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1207, %onnx::Conv_1208), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.2/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0, %onnx::Conv_1210, %onnx::Conv_1211), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv1/act/Relu_output_0, %onnx::Conv_1213, %onnx::Conv_1214), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.3/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.3/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.2/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.3 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0, %onnx::Conv_1216, %onnx::Conv_1217), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv1/act/Relu_output_0, %onnx::Conv_1219, %onnx::Conv_1220), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.4/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.4/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.3/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.4 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0, %onnx::Conv_1222, %onnx::Conv_1223), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv1/act/Relu_output_0, %onnx::Conv_1225, %onnx::Conv_1226), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.5/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.5/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.4/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.5 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0, %onnx::Conv_1228, %onnx::Conv_1229), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv1/act/Relu_output_0, %onnx::Conv_1231, %onnx::Conv_1232), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.6/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.6/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.5/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.6 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0, %onnx::Conv_1234, %onnx::Conv_1235), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv1/act/Relu_output_0, %onnx::Conv_1237, %onnx::Conv_1238), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.7/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.7/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.6/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.7 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0, %onnx::Conv_1240, %onnx::Conv_1241), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv1/act/Relu_output_0, %onnx::Conv_1243, %onnx::Conv_1244), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage3/stage3.1/blocks/blocks.8/Add\"](%/backbone/stage3/stage3.1/blocks/blocks.8/conv2/act/Relu_output_0, %/backbone/stage3/stage3.1/blocks/blocks.7/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.8 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage3/stage3.1/Concat_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage3/stage3.1/Concat\"](%/backbone/stage3/stage3.1/blocks/blocks.8/Add_output_0, %/backbone/stage3/stage3.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage3/stage3.1/final_conv/conv/Conv\"](%/backbone/stage3/stage3.1/Concat_output_0, %onnx::Conv_1246, %onnx::Conv_1247), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage3/stage3.1/final_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage3/stage3.1/final_conv/act/Relu\"](%/backbone/stage3/stage3.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage3/sscma.models.layers.csp_layer.CSPLayer::stage3.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.0/conv/conv/Conv_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/backbone/stage4/stage4.0/conv/conv/Conv\"](%/backbone/stage3/stage3.1/final_conv/act/Relu_output_0, %onnx::Conv_1249, %onnx::Conv_1250), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.0/conv/act/Relu_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.0/conv/act/Relu\"](%/backbone/stage4/stage4.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.base.conv_module.ConvModule::stage4.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/short_conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1252, %onnx::Conv_1253), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/short_conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/short_conv/act/Relu\"](%/backbone/stage4/stage4.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/main_conv/conv/Conv\"](%/backbone/stage4/stage4.0/conv/act/Relu_output_0, %onnx::Conv_1255, %onnx::Conv_1256), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/main_conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/main_conv/act/Relu\"](%/backbone/stage4/stage4.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/main_conv/act/Relu_output_0, %onnx::Conv_1258, %onnx::Conv_1259), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1261, %onnx::Conv_1262), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.0/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.0/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/main_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0, %onnx::Conv_1264, %onnx::Conv_1265), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv1/act/Relu_output_0, %onnx::Conv_1267, %onnx::Conv_1268), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.1/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.1/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.0/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0, %onnx::Conv_1270, %onnx::Conv_1271), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv1/act/Relu_output_0, %onnx::Conv_1273, %onnx::Conv_1274), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/backbone/stage4/stage4.1/blocks/blocks.2/Add\"](%/backbone/stage4/stage4.1/blocks/blocks.2/conv2/act/Relu_output_0, %/backbone/stage4/stage4.1/blocks/blocks.1/Add_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.2 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:120:0\n",
            "  %/backbone/stage4/stage4.1/Concat_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.1/Concat\"](%/backbone/stage4/stage4.1/blocks/blocks.2/Add_output_0, %/backbone/stage4/stage4.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.1/final_conv/conv/Conv\"](%/backbone/stage4/stage4.1/Concat_output_0, %onnx::Conv_1276, %onnx::Conv_1277), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.1/final_conv/act/Relu_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.1/final_conv/act/Relu\"](%/backbone/stage4/stage4.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.csp_layer.CSPLayer::stage4.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/conv/Conv\"](%/backbone/stage4/stage4.1/final_conv/act/Relu_output_0, %onnx::Conv_1279, %onnx::Conv_1280), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv1/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/backbone/stage4/stage4.2/poolings/MaxPool_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings/MaxPool\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_1/MaxPool\"](%/backbone/stage4/stage4.2/poolings/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/poolings_2/MaxPool\"](%/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/torch.nn.modules.pooling.MaxPool2d::poolings # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:782:0\n",
            "  %/backbone/stage4/stage4.2/Concat_output_0 : Float(1, 320, 3, 3, strides=[2880, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/backbone/stage4/stage4.2/Concat\"](%/backbone/stage4/stage4.2/conv1/conv/act/Relu_output_0, %/backbone/stage4/stage4.2/poolings/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_1/MaxPool_output_0, %/backbone/stage4/stage4.2/poolings_2/MaxPool_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2 # /content/ModelAssistant/sscma/models/layers/sppf.py:57:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/Concat_output_0, %onnx::Conv_1282, %onnx::Conv_1283), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/backbone/stage4/stage4.2/conv2/conv/act/Relu\"](%/backbone/stage4/stage4.2/conv2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet::backbone/torch.nn.modules.container.Sequential::stage4/sscma.models.layers.sppf.SPPFBottleneck::stage4.2/sscma.models.base.conv_module.ConvModule::conv2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/reduce_layers.2/conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/reduce_layers.2/conv/conv/Conv\"](%/backbone/stage4/stage4.2/conv2/conv/act/Relu_output_0, %onnx::Conv_1285, %onnx::Conv_1286), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/reduce_layers.2/conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/reduce_layers.2/conv/act/Relu\"](%/neck/reduce_layers.2/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::reduce_layers.2/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.0/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.0/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.0/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.0/Resize_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.0/Resize\"](%/neck/reduce_layers.2/conv/act/Relu_output_0, %/neck/upsample_layers.0/Constant_1_output_0, %/neck/upsample_layers.0/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_output_0 : Float(1, 160, 6, 6, strides=[5760, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat\"](%/neck/upsample_layers.0/Resize_output_0, %/backbone/stage3/stage3.1/final_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1288, %onnx::Conv_1289), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv\"](%/neck/Concat_output_0, %onnx::Conv_1291, %onnx::Conv_1292), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/main_conv/act/Relu_output_0, %onnx::Conv_1294, %onnx::Conv_1295), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1297, %onnx::Conv_1298), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/Concat\"](%/neck/top_down_layers.0/top_down_layers.0.0/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.0/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/Concat_output_0, %onnx::Conv_1300, %onnx::Conv_1301), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.0.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv\"](%/neck/top_down_layers.0/top_down_layers.0.0/final_conv/act/Relu_output_0, %onnx::Conv_1303, %onnx::Conv_1304), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.container.Sequential::top_down_layers.0/sscma.models.base.conv_module.ConvModule::top_down_layers.0.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/upsample_layers.1/Constant_output_0 : Float(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  2  2 [ CPUFloatType{4} ], onnx_name=\"/neck/upsample_layers.1/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Constant_1_output_0 : Float(0, strides=[1], device=cpu) = onnx::Constant[value=[ CPUFloatType{0} ], onnx_name=\"/neck/upsample_layers.1/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/upsample_layers.1/Resize_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Resize[coordinate_transformation_mode=\"asymmetric\", cubic_coeff_a=-0.75, mode=\"nearest\", nearest_mode=\"floor\", onnx_name=\"/neck/upsample_layers.1/Resize\"](%/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0, %/neck/upsample_layers.1/Constant_1_output_0, %/neck/upsample_layers.1/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/torch.nn.modules.upsampling.Upsample::upsample_layers.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:3931:0\n",
            "  %/neck/Concat_1_output_0 : Float(1, 80, 12, 12, strides=[11520, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_1\"](%/neck/upsample_layers.1/Resize_output_0, %/backbone/stage2/stage2.1/final_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:352:0\n",
            "  %/neck/top_down_layers.1/short_conv/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/short_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1306, %onnx::Conv_1307), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/short_conv/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/short_conv/act/Relu\"](%/neck/top_down_layers.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/main_conv/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/main_conv/conv/Conv\"](%/neck/Concat_1_output_0, %onnx::Conv_1309, %onnx::Conv_1310), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/main_conv/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/main_conv/act/Relu\"](%/neck/top_down_layers.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/top_down_layers.1/main_conv/act/Relu_output_0, %onnx::Conv_1312, %onnx::Conv_1313), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/top_down_layers.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1315, %onnx::Conv_1316), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 20, 12, 12, strides=[2880, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/top_down_layers.1/Concat_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/top_down_layers.1/Concat\"](%/neck/top_down_layers.1/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/top_down_layers.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/top_down_layers.1/final_conv/conv/Conv_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/top_down_layers.1/final_conv/conv/Conv\"](%/neck/top_down_layers.1/Concat_output_0, %onnx::Conv_1318, %onnx::Conv_1319), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/top_down_layers.1/final_conv/act/Relu_output_0 : Float(1, 40, 12, 12, strides=[5760, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/top_down_layers.1/final_conv/act/Relu\"](%/neck/top_down_layers.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::top_down_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.0/conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.0/conv/conv/Conv\"](%/neck/top_down_layers.1/final_conv/act/Relu_output_0, %onnx::Conv_1321, %onnx::Conv_1322), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.0/conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.0/conv/act/Relu\"](%/neck/downsample_layers.0/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.0/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_2_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_2\"](%/neck/downsample_layers.0/conv/act/Relu_output_0, %/neck/top_down_layers.0/top_down_layers.0.1/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/short_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1324, %onnx::Conv_1325), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/short_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/short_conv/act/Relu\"](%/neck/bottom_up_layers.0/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/main_conv/conv/Conv\"](%/neck/Concat_2_output_0, %onnx::Conv_1327, %onnx::Conv_1328), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/main_conv/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/main_conv/act/Relu\"](%/neck/bottom_up_layers.0/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.0/main_conv/act/Relu_output_0, %onnx::Conv_1330, %onnx::Conv_1331), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1333, %onnx::Conv_1334), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 40, 6, 6, strides=[1440, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.0/Concat_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.0/Concat\"](%/neck/bottom_up_layers.0/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/bottom_up_layers.0/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.0/final_conv/conv/Conv\"](%/neck/bottom_up_layers.0/Concat_output_0, %onnx::Conv_1336, %onnx::Conv_1337), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.0/final_conv/act/Relu_output_0 : Float(1, 80, 6, 6, strides=[2880, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.0/final_conv/act/Relu\"](%/neck/bottom_up_layers.0/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.0/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/downsample_layers.1/conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/neck/downsample_layers.1/conv/conv/Conv\"](%/neck/bottom_up_layers.0/final_conv/act/Relu_output_0, %onnx::Conv_1339, %onnx::Conv_1340), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/downsample_layers.1/conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/downsample_layers.1/conv/act/Relu\"](%/neck/downsample_layers.1/conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.base.conv_module.ConvModule::downsample_layers.1/sscma.models.base.general.ConvNormActivation::conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/Concat_3_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/Concat_3\"](%/neck/downsample_layers.1/conv/act/Relu_output_0, %/neck/reduce_layers.2/conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck # /content/ModelAssistant/sscma/models/necks/fpn.py:364:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/short_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1342, %onnx::Conv_1343), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/short_conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/short_conv/act/Relu\"](%/neck/bottom_up_layers.1/short_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::short_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/main_conv/conv/Conv\"](%/neck/Concat_3_output_0, %onnx::Conv_1345, %onnx::Conv_1346), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/main_conv/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/main_conv/act/Relu\"](%/neck/bottom_up_layers.1/main_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::main_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv\"](%/neck/bottom_up_layers.1/main_conv/act/Relu_output_0, %onnx::Conv_1348, %onnx::Conv_1349), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv1/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv1/act/Relu_output_0, %onnx::Conv_1351, %onnx::Conv_1352), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu_output_0 : Float(1, 80, 3, 3, strides=[720, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/torch.nn.modules.container.Sequential::blocks/sscma.models.layers.csp_layer.DarknetBottleneck::blocks.0/sscma.models.base.general.ConvNormActivation::conv2/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/neck/bottom_up_layers.1/Concat_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/neck/bottom_up_layers.1/Concat\"](%/neck/bottom_up_layers.1/blocks/blocks.0/conv2/act/Relu_output_0, %/neck/bottom_up_layers.1/short_conv/act/Relu_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1 # /content/ModelAssistant/sscma/models/layers/csp_layer.py:69:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/neck/bottom_up_layers.1/final_conv/conv/Conv\"](%/neck/bottom_up_layers.1/Concat_output_0, %onnx::Conv_1354, %onnx::Conv_1355), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.conv.Conv2d::conv # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/neck/bottom_up_layers.1/final_conv/act/Relu_output_0 : Float(1, 160, 3, 3, strides=[1440, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name=\"/neck/bottom_up_layers.1/final_conv/act/Relu\"](%/neck/bottom_up_layers.1/final_conv/conv/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/sscma.models.necks.fpn.YOLOv5PAFPN::neck/sscma.models.layers.csp_layer.CSPLayer::bottom_up_layers.1/sscma.models.base.general.ConvNormActivation::final_conv/torch.nn.modules.activation.ReLU::act # /usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1457:0\n",
            "  %/convs_pred.0/Conv_output_0 : Float(1, 18, 12, 12, strides=[2592, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.0/Conv\"](%/neck/top_down_layers.1/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.0.weight, %bbox_head.head_module.convs_pred.0.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.0 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_output_0 : Float(1, 18, 12, 12, strides=[2592, 144, 12, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid\"](%/convs_pred.0/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3    6  144 [ CPULongType{4} ], onnx_name=\"/Constant\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_output_0 : Float(1, 3, 6, 144, strides=[2592, 864, 144, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape\"](%/Sigmoid_output_0, %/Constant_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_output_0 : Float(1, 3, 144, 6, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose\"](%/Reshape_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.1/Conv_output_0 : Float(1, 18, 6, 6, strides=[648, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.1/Conv\"](%/neck/bottom_up_layers.0/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.1.weight, %bbox_head.head_module.convs_pred.1.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.1 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_1_output_0 : Float(1, 18, 6, 6, strides=[648, 36, 6, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_1\"](%/convs_pred.1/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_1_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3   6  36 [ CPULongType{4} ], onnx_name=\"/Constant_1\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_1_output_0 : Float(1, 3, 6, 36, strides=[648, 216, 36, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_1\"](%/Sigmoid_1_output_0, %/Constant_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_1_output_0 : Float(1, 3, 36, 6, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_1\"](%/Reshape_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/convs_pred.2/Conv_output_0 : Float(1, 18, 3, 3, strides=[162, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1], onnx_name=\"/convs_pred.2/Conv\"](%/neck/bottom_up_layers.1/final_conv/act/Relu_output_0, %bbox_head.head_module.convs_pred.2.weight, %bbox_head.head_module.convs_pred.2.bias), scope: sscma.models.detectors.yolov5_detector.YOLODetector::/torch.nn.modules.conv.Conv2d::convs_pred.2 # /usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:459:0\n",
            "  %/Sigmoid_2_output_0 : Float(1, 18, 3, 3, strides=[162, 9, 3, 1], requires_grad=0, device=cpu) = onnx::Sigmoid[onnx_name=\"/Sigmoid_2\"](%/convs_pred.2/Conv_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:112:0\n",
            "  %/Constant_2_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  3  6  9 [ CPULongType{4} ], onnx_name=\"/Constant_2\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Reshape_2_output_0 : Float(1, 3, 6, 9, strides=[162, 54, 9, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_2\"](%/Sigmoid_2_output_0, %/Constant_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:114:0\n",
            "  %/Transpose_2_output_0 : Float(1, 3, 9, 6, strides=[162, 54, 6, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name=\"/Transpose_2\"](%/Reshape_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:115:0\n",
            "  %/Constant_3_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 12  12 [ CPULongType{2} ], onnx_name=\"/Constant_3\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_4_output_0 : Long(12, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_4\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_output_0 : Long(12, 12, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand\"](%/Constant_4_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_5_output_0 : Long(1, 12, strides=[12, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/Constant_5\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_1_output_0 : Long(12, 12, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_1\"](%/Constant_5_output_0, %/Constant_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze\"](%/Expand_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_1_output_0 : Long(12, 12, 1, strides=[12, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_1\"](%/Expand_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_output_0 : Long(12, 12, 2, strides=[24, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat\"](%/Unsqueeze_output_0, %/Unsqueeze_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_6_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   1  12  12   2 [ CPULongType{5} ], onnx_name=\"/Constant_6\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_7\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape\"](%/Constant_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_8_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_8\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/ConstantOfShape_output_0, %/Constant_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal\"](%/Constant_6_output_0, %/Mul_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where\"](%/Equal_output_0, %/ConstantOfShape_output_0, %/Constant_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_2_output_0 : Long(1, 1, 12, 12, 2, strides=[288, 288, 24, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_2\"](%/Concat_output_0, %/Where_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_9\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_3_output_0 : Long(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_3\"](%/Expand_2_output_0, %/Constant_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast\"](%/Reshape_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_1_output_0 : Float(1, 1, 144, 2, strides=[288, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_1\"](%/Cast_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_902 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    10  13  (1,2,.,.) =    16  30  (1,3,.,.) =    33  23 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_10_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=   1    3  144    2 [ CPULongType{4} ], onnx_name=\"/Constant_10\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_11\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_1\"](%/Constant_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_12\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/ConstantOfShape_1_output_0, %/Constant_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_1\"](%/Constant_10_output_0, %/Mul_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_1\"](%/Equal_1_output_0, %/ConstantOfShape_1_output_0, %/Constant_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_3_output_0 : Long(1, 3, 144, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_3\"](%onnx::Expand_902, %/Where_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_2_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_2\"](%/Expand_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_3_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_3\"](%/Cast_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_output_0 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu), %/Split_output_1 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu), %/Split_output_2 : Float(1, 3, 144, 2, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split\"](%/Transpose_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_13\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_2_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_2\"](%/Split_output_0, %/Constant_13_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_14\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub\"](%/Mul_2_output_0, %/Constant_14_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Sub_output_0, %/Cast_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant_15\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_3_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_3\"](%/Add_output_0, %/Constant_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_16\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_4_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_4\"](%/Split_output_1, %/Constant_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_5_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_5\"](%/Mul_4_output_0, %/Mul_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_6_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_6\"](%/Mul_5_output_0, %/Cast_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_17\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_7_output_0 : Float(1, 3, 144, 2, strides=[864, 288, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_7\"](%/Split_output_2, %/Constant_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_1_output_0 : Float(1, 3, 144, 6, strides=[2592, 864, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_1\"](%/Mul_3_output_0, %/Mul_6_output_0, %/Mul_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_18_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_18\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_4_output_0 : Float(1, 432, 6, strides=[2592, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_4\"](%/Concat_1_output_0, %/Constant_18_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_19_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 6  6 [ CPULongType{2} ], onnx_name=\"/Constant_19\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_20_output_0 : Long(6, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{6,1} ], onnx_name=\"/Constant_20\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_4_output_0 : Long(6, 6, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_4\"](%/Constant_20_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_21_output_0 : Long(1, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2  3  4  5 [ CPULongType{1,6} ], onnx_name=\"/Constant_21\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_5_output_0 : Long(6, 6, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_5\"](%/Constant_21_output_0, %/Constant_19_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_2_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_2\"](%/Expand_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_3_output_0 : Long(6, 6, 1, strides=[6, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_3\"](%/Expand_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_2_output_0 : Long(6, 6, 2, strides=[12, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_2\"](%/Unsqueeze_2_output_0, %/Unsqueeze_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_22_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  6  6  2 [ CPULongType{5} ], onnx_name=\"/Constant_22\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_23\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_2\"](%/Constant_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_24_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_24\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_8_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_8\"](%/ConstantOfShape_2_output_0, %/Constant_24_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_2_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_2\"](%/Constant_22_output_0, %/Mul_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_2_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_2\"](%/Equal_2_output_0, %/ConstantOfShape_2_output_0, %/Constant_22_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_6_output_0 : Long(1, 1, 6, 6, 2, strides=[72, 72, 12, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_6\"](%/Concat_2_output_0, %/Where_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_25_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_25\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_5_output_0 : Long(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_5\"](%/Expand_6_output_0, %/Constant_25_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_4_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_4\"](%/Reshape_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_5_output_0 : Float(1, 1, 36, 2, strides=[72, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_5\"](%/Cast_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_982 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    30  61  (1,2,.,.) =    62  45  (1,3,.,.) =     59  119 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_26_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value=  1   3  36   2 [ CPULongType{4} ], onnx_name=\"/Constant_26\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_27\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_3\"](%/Constant_27_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_28_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_28\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_9\"](%/ConstantOfShape_3_output_0, %/Constant_28_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_3\"](%/Constant_26_output_0, %/Mul_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_3\"](%/Equal_3_output_0, %/ConstantOfShape_3_output_0, %/Constant_26_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_7_output_0 : Long(1, 3, 36, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_7\"](%onnx::Expand_982, %/Where_3_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_6_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_6\"](%/Expand_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_7_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_7\"](%/Cast_6_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_1_output_0 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu), %/Split_1_output_1 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu), %/Split_1_output_2 : Float(1, 3, 36, 2, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split_1\"](%/Transpose_1_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_29_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_29\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_10_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_10\"](%/Split_1_output_0, %/Constant_29_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_30_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_30\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_1_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_1\"](%/Mul_10_output_0, %/Constant_30_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_1_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Sub_1_output_0, %/Cast_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_31_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={16}, onnx_name=\"/Constant_31\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_11_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_11\"](%/Add_1_output_0, %/Constant_31_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_32_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_32\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_12_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_12\"](%/Split_1_output_1, %/Constant_32_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_13_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_13\"](%/Mul_12_output_0, %/Mul_12_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_14_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_14\"](%/Mul_13_output_0, %/Cast_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_33_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_33\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_15_output_0 : Float(1, 3, 36, 2, strides=[216, 72, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_15\"](%/Split_1_output_2, %/Constant_33_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_3_output_0 : Float(1, 3, 36, 6, strides=[648, 216, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_3\"](%/Mul_11_output_0, %/Mul_14_output_0, %/Mul_15_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_34_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_34\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_6_output_0 : Float(1, 108, 6, strides=[648, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_6\"](%/Concat_3_output_0, %/Constant_34_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Constant_35_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 3  3 [ CPULongType{2} ], onnx_name=\"/Constant_35\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Constant_36_output_0 : Long(3, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2 [ CPULongType{3,1} ], onnx_name=\"/Constant_36\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_8_output_0 : Long(3, 3, strides=[1, 0], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_8\"](%/Constant_36_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Constant_37_output_0 : Long(1, 3, strides=[3, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  2 [ CPULongType{1,3} ], onnx_name=\"/Constant_37\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/functional.py:504:0\n",
            "  %/Expand_9_output_0 : Long(3, 3, strides=[0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_9\"](%/Constant_37_output_0, %/Constant_35_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector::\n",
            "  %/Unsqueeze_4_output_0 : Long(3, 3, 1, strides=[3, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_4\"](%/Expand_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Unsqueeze_5_output_0 : Long(3, 3, 1, strides=[3, 1, 1], device=cpu) = onnx::Unsqueeze[axes=[2], onnx_name=\"/Unsqueeze_5\"](%/Expand_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Concat_4_output_0 : Long(3, 3, 2, strides=[6, 2, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=2, onnx_name=\"/Concat_4\"](%/Unsqueeze_4_output_0, %/Unsqueeze_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_38_output_0 : Long(5, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  3  3  2 [ CPULongType{5} ], onnx_name=\"/Constant_38\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name=\"/Constant_39\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/ConstantOfShape_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_4\"](%/Constant_39_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_40_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_40\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Mul_16_output_0 : Long(5, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_16\"](%/ConstantOfShape_4_output_0, %/Constant_40_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Equal_4_output_0 : Bool(5, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_4\"](%/Constant_38_output_0, %/Mul_16_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Where_4_output_0 : Long(5, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_4\"](%/Equal_4_output_0, %/ConstantOfShape_4_output_0, %/Constant_38_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Expand_10_output_0 : Long(1, 1, 3, 3, 2, strides=[18, 18, 6, 2, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_10\"](%/Concat_4_output_0, %/Where_4_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Constant_41_output_0 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 1  1 -1  2 [ CPULongType{4} ], onnx_name=\"/Constant_41\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Reshape_7_output_0 : Long(1, 1, 9, 2, strides=[18, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_7\"](%/Expand_10_output_0, %/Constant_41_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_8_output_0 : Float(1, 1, 9, 2, strides=[18, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_8\"](%/Reshape_7_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %/Cast_9_output_0 : Float(1, 1, 9, 2, strides=[18, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_9\"](%/Cast_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:143:0\n",
            "  %onnx::Expand_1061 : Long(1, 3, 1, 2, strides=[6, 2, 2, 1], requires_grad=0, device=cpu) = onnx::Constant[value=(1,1,.,.) =    116   90  (1,2,.,.) =    156  198  (1,3,.,.) =    373  326 [ CPULongType{1,3,1,2} ]]()\n",
            "  %/Constant_42_output_0 : Long(4, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  3  9  2 [ CPULongType{4} ], onnx_name=\"/Constant_42\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_43_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name=\"/Constant_43\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name=\"/ConstantOfShape_5\"](%/Constant_43_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Constant_44_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_44\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Mul_17_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name=\"/Mul_17\"](%/ConstantOfShape_5_output_0, %/Constant_44_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name=\"/Equal_5\"](%/Constant_42_output_0, %/Mul_17_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name=\"/Where_5\"](%/Equal_5_output_0, %/ConstantOfShape_5_output_0, %/Constant_42_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Expand_11_output_0 : Long(1, 3, 9, 2, strides=[6, 2, 0, 1], requires_grad=0, device=cpu) = onnx::Expand[onnx_name=\"/Expand_11\"](%onnx::Expand_1061, %/Where_5_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:148:0\n",
            "  %/Cast_10_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_10\"](%/Expand_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:149:0\n",
            "  %/Cast_11_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name=\"/Cast_11\"](%/Cast_10_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:150:0\n",
            "  %/Split_2_output_0 : Float(1, 3, 9, 2, strides=[162, 54, 6, 1], requires_grad=0, device=cpu), %/Split_2_output_1 : Float(1, 3, 9, 2, strides=[162, 54, 6, 1], requires_grad=0, device=cpu), %/Split_2_output_2 : Float(1, 3, 9, 2, strides=[162, 54, 6, 1], requires_grad=0, device=cpu) = onnx::Split[axis=-1, split=[2, 2, 2], onnx_name=\"/Split_2\"](%/Transpose_2_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /usr/local/lib/python3.11/dist-packages/torch/_tensor.py:803:0\n",
            "  %/Constant_45_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_45\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_18_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_18\"](%/Split_2_output_0, %/Constant_45_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_46_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_46\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Sub_2_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name=\"/Sub_2\"](%/Mul_18_output_0, %/Constant_46_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Add_2_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name=\"/Add_2\"](%/Sub_2_output_0, %/Cast_9_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_47_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={32}, onnx_name=\"/Constant_47\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Mul_19_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_19\"](%/Add_2_output_0, %/Constant_47_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:125:0\n",
            "  %/Constant_48_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant_48\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_20_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_20\"](%/Split_2_output_1, %/Constant_48_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:128:0\n",
            "  %/Mul_21_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_21\"](%/Mul_20_output_0, %/Mul_20_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:129:0\n",
            "  %/Mul_22_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_22\"](%/Mul_21_output_0, %/Cast_11_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:130:0\n",
            "  %/Constant_49_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={100}, onnx_name=\"/Constant_49\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Mul_23_output_0 : Float(1, 3, 9, 2, strides=[54, 18, 2, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_23\"](%/Split_2_output_2, %/Constant_49_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:131:0\n",
            "  %/Concat_5_output_0 : Float(1, 3, 9, 6, strides=[162, 54, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=-1, onnx_name=\"/Concat_5\"](%/Mul_19_output_0, %/Mul_22_output_0, %/Mul_23_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:132:0\n",
            "  %/Constant_50_output_0 : Long(3, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1 -1  6 [ CPULongType{3} ], onnx_name=\"/Constant_50\"](), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %/Reshape_8_output_0 : Float(1, 27, 6, strides=[162, 6, 1], requires_grad=0, device=cpu) = onnx::Reshape[onnx_name=\"/Reshape_8\"](%/Concat_5_output_0, %/Constant_50_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:133:0\n",
            "  %output : Float(1, 567, 6, strides=[3402, 6, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name=\"/Concat_6\"](%/Reshape_4_output_0, %/Reshape_6_output_0, %/Reshape_8_output_0), scope: sscma.models.detectors.yolov5_detector.YOLODetector:: # /content/ModelAssistant/sscma/models/heads/yolov5_head.py:135:0\n",
            "  return (%output)\n",
            "\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "ONNX: Successfully export model: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.onnx\n",
            "pnnxparam = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.pnnx.param\n",
            "pnnxbin = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.pnnx.bin\n",
            "pnnxpy = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.pnnx.py\n",
            "pnnxonnx = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.pnnx.onnx\n",
            "ncnnparam = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.ncnn.param\n",
            "ncnnbin = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.ncnn.bin\n",
            "ncnnpy = /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float.ncnn.py\n",
            "fp16 = 1\n",
            "optlevel = 2\n",
            "device = cpu\n",
            "inputshape = [1,3,96,96]f32\n",
            "inputshape2 = \n",
            "customop = \n",
            "moduleop = \n",
            "############# pass_level0\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "inline module = sscma.models.backbones.csp_darknet.YOLOv5CSPDarknet\n",
            "inline module = sscma.models.base.conv_module.ConvModule\n",
            "inline module = sscma.models.base.general.ConvNormActivation\n",
            "inline module = sscma.models.layers.csp_layer.CSPLayer\n",
            "inline module = sscma.models.layers.csp_layer.DarknetBottleneck\n",
            "inline module = sscma.models.layers.sppf.SPPFBottleneck\n",
            "inline module = sscma.models.necks.fpn.YOLOv5PAFPN\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "\n",
            "----------------\n",
            "\n",
            "############# pass_level1\n",
            "############# pass_level2\n",
            "############# pass_level3\n",
            "############# pass_level4\n",
            "############# pass_level5\n",
            "############# pass_ncnn\n"
          ]
        }
      ],
      "source": [
        "!sscma.export configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-k_Mqsz5zfV"
      },
      "source": [
        "### 📝Evaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uupbDApm5zfV"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A11V_dGA5zfV",
        "outputId": "81e9bfab-979a-4384-cca3-45550eb51946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100.pkl\n",
            "08/04 18:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1321478210\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1321478210\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 18:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_182037'}\n",
            "2025-08-04 18:20:39.187670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754331639.210368   29482 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754331639.217348   29482 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 18:20:39.240234: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 18:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 18:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "Loads checkpoint by local backend from path: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100.pth\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.20s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.768\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.978\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.922\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.332\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.774\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.809\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.814\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.815\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.820\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFy9IAvo5zfV"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReZqrRCx5zfV",
        "outputId": "b602140f-2fc5-45c2-a194-19627b952c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.pkl\n",
            "08/04 18:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 813673306\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 813673306\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 18:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_182111'}\n",
            "2025-08-04 18:21:13.532843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754331673.555522   29656 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754331673.562521   29656 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 18:21:13.585469: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 18:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 18:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/348 [00:00<?, ?it/s]08/04 18:21:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "08/04 18:21:19 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 348/348 [00:03<00:00, 95.05it/s] \n",
            "08/04 18:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "08/04 18:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.766 0.977 0.919 -1.000 0.277 0.770\n",
            "{'coco/bbox_mAP': 0.766, 'coco/bbox_mAP_50': 0.977, 'coco/bbox_mAP_75': 0.919, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.277, 'coco/bbox_mAP_l': 0.77}\n",
            "FPS: 285.856427 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aWTGCUH5zfV"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9Oowntc5zfW",
        "outputId": "631ca55e-f047-46ac-baaf-33aef0c20297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.pkl\n",
            "08/04 18:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 437420294\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 437420294\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 18:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_float32.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_182136'}\n",
            "2025-08-04 18:21:38.483146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754331698.506113   29784 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754331698.512980   29784 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 18:21:38.535395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 18:21:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 18:21:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/348 [00:00<?, ?it/s]08/04 18:21:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "08/04 18:21:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 348/348 [00:03<00:00, 95.90it/s] \n",
            "08/04 18:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.11s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.766\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.977\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.919\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.277\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.806\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.812\n",
            "08/04 18:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.766 0.977 0.919 -1.000 0.277 0.770\n",
            "{'coco/bbox_mAP': 0.766, 'coco/bbox_mAP_50': 0.977, 'coco/bbox_mAP_75': 0.919, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.277, 'coco/bbox_mAP_l': 0.77}\n",
            "FPS: 266.363430 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUbSAHuH5zfW"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxZ_BYj45zfW",
        "outputId": "5952945c-20a6-46f3-fdde-80df361f3431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.0\n",
            "Using task type from config: mmdet\n",
            "Using dump path from checkpoint: /content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_int8.pkl\n",
            "08/04 18:22:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1162372659\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.0.0+cu117\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.7\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.5\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.15.1+cu117\n",
            "    OpenCV: 4.11.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1162372659\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "08/04 18:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "affine_scale = 0.5\n",
            "albu_train_transforms = [\n",
            "    dict(p=0.01, type='Blur'),\n",
            "    dict(p=0.01, type='MedianBlur'),\n",
            "    dict(p=0.01, type='ToGray'),\n",
            "    dict(p=0.01, type='CLAHE'),\n",
            "]\n",
            "anchors = [\n",
            "    [\n",
            "        (\n",
            "            10,\n",
            "            13,\n",
            "        ),\n",
            "        (\n",
            "            16,\n",
            "            30,\n",
            "        ),\n",
            "        (\n",
            "            33,\n",
            "            23,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            30,\n",
            "            61,\n",
            "        ),\n",
            "        (\n",
            "            62,\n",
            "            45,\n",
            "        ),\n",
            "        (\n",
            "            59,\n",
            "            119,\n",
            "        ),\n",
            "    ],\n",
            "    [\n",
            "        (\n",
            "            116,\n",
            "            90,\n",
            "        ),\n",
            "        (\n",
            "            156,\n",
            "            198,\n",
            "        ),\n",
            "        (\n",
            "            373,\n",
            "            326,\n",
            "        ),\n",
            "    ],\n",
            "]\n",
            "batch = 16\n",
            "batch_shapes_cfg = dict(\n",
            "    batch_size=1,\n",
            "    extra_pad_ratio=0.5,\n",
            "    img_size=96,\n",
            "    size_divisor=32,\n",
            "    type='BatchShapePolicy')\n",
            "custom_hooks = [\n",
            "    dict(\n",
            "        ema_type='ExpMomentumEMA',\n",
            "        momentum=0.0001,\n",
            "        priority=49,\n",
            "        strict_load=False,\n",
            "        type='EMAHook',\n",
            "        update_buffers=True),\n",
            "]\n",
            "data_root = 'BokChoy_Disease_Swift-YOLO_96/dataset/'\n",
            "dataset_type = 'sscma.CustomYOLOv5CocoDataset'\n",
            "deepen_factor = 0.33\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=5, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(interval=100, type='sscma.TextLoggerHook'),\n",
            "    param_scheduler=dict(\n",
            "        lr_factor=0.01,\n",
            "        max_epochs=100,\n",
            "        scheduler_type='linear',\n",
            "        type='YOLOv5ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook'))\n",
            "default_scope = 'sscma'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "epochs = 100\n",
            "height = 96\n",
            "imgsz = (\n",
            "    96,\n",
            "    96,\n",
            ")\n",
            "input_type = 'image'\n",
            "launcher = 'none'\n",
            "load_from = 'BokChoy_Disease_Swift-YOLO_96/pretrain.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
            "loss_bbox_weight = 0.05\n",
            "loss_cls_weight = 0.5\n",
            "loss_obj_weight = 1.0\n",
            "lr = 0.01\n",
            "lr_factor = 0.01\n",
            "max_keep_ckpts = 3\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        type='YOLOv5CSPDarknet',\n",
            "        widen_factor=0.15),\n",
            "    bbox_head=dict(\n",
            "        head_module=dict(\n",
            "            featmap_strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            in_channels=[\n",
            "                256,\n",
            "                512,\n",
            "                1024,\n",
            "            ],\n",
            "            num_base_priors=3,\n",
            "            num_classes=1,\n",
            "            type='sscma.DetHead',\n",
            "            widen_factor=0.15),\n",
            "        loss_bbox=dict(\n",
            "            bbox_format='xywh',\n",
            "            eps=1e-07,\n",
            "            iou_mode='ciou',\n",
            "            loss_weight=0.05,\n",
            "            reduction='mean',\n",
            "            return_iou=True,\n",
            "            type='IoULoss'),\n",
            "        loss_cls=dict(\n",
            "            loss_weight=0.006250000000000001,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        loss_obj=dict(\n",
            "            loss_weight=0.022500000000000003,\n",
            "            reduction='mean',\n",
            "            type='mmdet.CrossEntropyLoss',\n",
            "            use_sigmoid=True),\n",
            "        obj_level_weights=[\n",
            "            4.0,\n",
            "            1.0,\n",
            "            0.4,\n",
            "        ],\n",
            "        prior_generator=dict(\n",
            "            base_sizes=[\n",
            "                [\n",
            "                    (\n",
            "                        10,\n",
            "                        13,\n",
            "                    ),\n",
            "                    (\n",
            "                        16,\n",
            "                        30,\n",
            "                    ),\n",
            "                    (\n",
            "                        33,\n",
            "                        23,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        30,\n",
            "                        61,\n",
            "                    ),\n",
            "                    (\n",
            "                        62,\n",
            "                        45,\n",
            "                    ),\n",
            "                    (\n",
            "                        59,\n",
            "                        119,\n",
            "                    ),\n",
            "                ],\n",
            "                [\n",
            "                    (\n",
            "                        116,\n",
            "                        90,\n",
            "                    ),\n",
            "                    (\n",
            "                        156,\n",
            "                        198,\n",
            "                    ),\n",
            "                    (\n",
            "                        373,\n",
            "                        326,\n",
            "                    ),\n",
            "                ],\n",
            "            ],\n",
            "            strides=[\n",
            "                8,\n",
            "                16,\n",
            "                32,\n",
            "            ],\n",
            "            type='mmdet.YOLOAnchorGenerator'),\n",
            "        prior_match_thr=4.0,\n",
            "        type='sscma.YOLOV5Head'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            0.0,\n",
            "            0.0,\n",
            "            0.0,\n",
            "        ],\n",
            "        std=[\n",
            "            255.0,\n",
            "            255.0,\n",
            "            255.0,\n",
            "        ],\n",
            "        type='mmdet.DetDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        act_cfg=dict(inplace=True, type='ReLU'),\n",
            "        deepen_factor=0.33,\n",
            "        in_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        norm_cfg=dict(eps=0.001, momentum=0.03, type='BN'),\n",
            "        num_csp_blocks=3,\n",
            "        out_channels=[\n",
            "            256,\n",
            "            512,\n",
            "            1024,\n",
            "        ],\n",
            "        type='YOLOv5PAFPN',\n",
            "        widen_factor=0.15),\n",
            "    test_cfg=dict(\n",
            "        max_per_img=300,\n",
            "        multi_label=True,\n",
            "        nms=dict(iou_threshold=0.65, type='nms'),\n",
            "        nms_pre=30000,\n",
            "        score_thr=0.001),\n",
            "    type='sscma.YOLODetector')\n",
            "model_test_cfg = dict(\n",
            "    max_per_img=300,\n",
            "    multi_label=True,\n",
            "    nms=dict(iou_threshold=0.65, type='nms'),\n",
            "    nms_pre=30000,\n",
            "    score_thr=0.001)\n",
            "momentum = 0.937\n",
            "norm_cfg = dict(eps=0.001, momentum=0.03, type='BN')\n",
            "num_classes = 1\n",
            "num_det_layers = 3\n",
            "obj_level_weights = [\n",
            "    4.0,\n",
            "    1.0,\n",
            "    0.4,\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    constructor='YOLOv5OptimizerConstructor',\n",
            "    optimizer=dict(\n",
            "        batch_size_per_gpu=16,\n",
            "        lr=0.01,\n",
            "        momentum=0.937,\n",
            "        nesterov=True,\n",
            "        type='SGD',\n",
            "        weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = None\n",
            "persistent_workers = True\n",
            "pre_transform = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "]\n",
            "prior_match_thr = 4.0\n",
            "resume = False\n",
            "save_interval = 5\n",
            "strides = [\n",
            "    8,\n",
            "    16,\n",
            "    32,\n",
            "]\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=dict(\n",
            "            batch_size=1,\n",
            "            extra_pad_ratio=0.5,\n",
            "            img_size=96,\n",
            "            size_divisor=32,\n",
            "            type='BatchShapePolicy'),\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    dict(\n",
            "        ann_file=\n",
            "        'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "        metric='bbox',\n",
            "        proposal_nums=(\n",
            "            100,\n",
            "            1,\n",
            "            10,\n",
            "        ),\n",
            "        type='mmdet.CocoMetric'),\n",
            "    dict(\n",
            "        out_file_path=\n",
            "        '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/epoch_100_int8.pkl',\n",
            "        type='DumpResults'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(scale=(\n",
            "        96,\n",
            "        96,\n",
            "    ), type='YOLOv5KeepRatioResize'),\n",
            "    dict(\n",
            "        allow_scale_up=False,\n",
            "        pad_val=dict(img=114),\n",
            "        scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        type='sscma.LetterResize'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'scale_factor',\n",
            "            'pad_param',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "train_ann = 'train/_annotations.coco.json'\n",
            "train_cfg = dict(max_epochs=100, type='EpochBasedTrainLoop', val_interval=5)\n",
            "train_data = 'train/'\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='train/_annotations.coco.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                _scope_='sscma',\n",
            "                img_scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                pad_val=114.0,\n",
            "                pre_transform=[\n",
            "                    dict(\n",
            "                        file_client_args=dict(backend='disk'),\n",
            "                        type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations', with_bbox=True),\n",
            "                ],\n",
            "                type='Mosaic'),\n",
            "            dict(\n",
            "                border=(\n",
            "                    -48,\n",
            "                    -48,\n",
            "                ),\n",
            "                border_val=(\n",
            "                    114,\n",
            "                    114,\n",
            "                    114,\n",
            "                ),\n",
            "                max_rotate_degree=0.0,\n",
            "                max_shear_degree=0.0,\n",
            "                scaling_ratio_range=(\n",
            "                    0.5,\n",
            "                    1.5,\n",
            "                ),\n",
            "                type='YOLOv5RandomAffine'),\n",
            "            dict(\n",
            "                bbox_params=dict(\n",
            "                    format='pascal_voc',\n",
            "                    label_fields=[\n",
            "                        'gt_bboxes_labels',\n",
            "                        'gt_ignore_flags',\n",
            "                    ],\n",
            "                    type='BboxParams'),\n",
            "                keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "                transforms=[\n",
            "                    dict(p=0.01, type='Blur'),\n",
            "                    dict(p=0.01, type='MedianBlur'),\n",
            "                    dict(p=0.01, type='ToGray'),\n",
            "                    dict(p=0.01, type='CLAHE'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "            dict(type='YOLOv5HSVRandomAug'),\n",
            "            dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'flip',\n",
            "                    'flip_direction',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        _scope_='sscma',\n",
            "        img_scale=(\n",
            "            96,\n",
            "            96,\n",
            "        ),\n",
            "        pad_val=114.0,\n",
            "        pre_transform=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "        ],\n",
            "        type='Mosaic'),\n",
            "    dict(\n",
            "        border=(\n",
            "            -48,\n",
            "            -48,\n",
            "        ),\n",
            "        border_val=(\n",
            "            114,\n",
            "            114,\n",
            "            114,\n",
            "        ),\n",
            "        max_rotate_degree=0.0,\n",
            "        max_shear_degree=0.0,\n",
            "        scaling_ratio_range=(\n",
            "            0.5,\n",
            "            1.5,\n",
            "        ),\n",
            "        type='YOLOv5RandomAffine'),\n",
            "    dict(\n",
            "        bbox_params=dict(\n",
            "            format='pascal_voc',\n",
            "            label_fields=[\n",
            "                'gt_bboxes_labels',\n",
            "                'gt_ignore_flags',\n",
            "            ],\n",
            "            type='BboxParams'),\n",
            "        keymap=dict(gt_bboxes='bboxes', img='image'),\n",
            "        transforms=[\n",
            "            dict(p=0.01, type='Blur'),\n",
            "            dict(p=0.01, type='MedianBlur'),\n",
            "            dict(p=0.01, type='ToGray'),\n",
            "            dict(p=0.01, type='CLAHE'),\n",
            "        ],\n",
            "        type='mmdet.Albu'),\n",
            "    dict(type='YOLOv5HSVRandomAug'),\n",
            "    dict(prob=0.5, type='mmdet.RandomFlip'),\n",
            "    dict(\n",
            "        meta_keys=(\n",
            "            'img_id',\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'flip',\n",
            "            'flip_direction',\n",
            "        ),\n",
            "        type='mmdet.PackDetInputs'),\n",
            "]\n",
            "val_ann = 'valid/_annotations.coco.json'\n",
            "val_batch = 16\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_data = 'valid/'\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='valid/_annotations.coco.json',\n",
            "        batch_shapes_cfg=None,\n",
            "        data_prefix=dict(img='valid/'),\n",
            "        data_root='BokChoy_Disease_Swift-YOLO_96/dataset/',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                file_client_args=dict(backend='disk'),\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                96,\n",
            "                96,\n",
            "            ), type='YOLOv5KeepRatioResize'),\n",
            "            dict(\n",
            "                allow_scale_up=False,\n",
            "                pad_val=dict(img=114),\n",
            "                scale=(\n",
            "                    96,\n",
            "                    96,\n",
            "                ),\n",
            "                type='sscma.LetterResize'),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_id',\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'scale_factor',\n",
            "                    'pad_param',\n",
            "                ),\n",
            "                type='mmdet.PackDetInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='sscma.CustomYOLOv5CocoDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=1,\n",
            "    persistent_workers=True,\n",
            "    pin_memory=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    ann_file=\n",
            "    'BokChoy_Disease_Swift-YOLO_96/dataset/valid/_annotations.coco.json',\n",
            "    metric='bbox',\n",
            "    proposal_nums=(\n",
            "        100,\n",
            "        1,\n",
            "        10,\n",
            "    ),\n",
            "    type='mmdet.CocoMetric')\n",
            "val_interval = 5\n",
            "val_workers = 2\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(type='TensorboardVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='sscma.FomoLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(type='TensorboardVisBackend'),\n",
            "    ])\n",
            "weight_decay = 0.0005\n",
            "widen_factor = 0.15\n",
            "width = 96\n",
            "work_dir = 'BokChoy_Disease_Swift-YOLO_96'\n",
            "workers = 2\n",
            "\n",
            "()\n",
            "{'vis_backends': [{'type': 'LocalVisBackend'}, {'type': 'TensorboardVisBackend'}], 'save_dir': '/content/ModelAssistant/BokChoy_Disease_Swift-YOLO_96/20250804_182200'}\n",
            "2025-08-04 18:22:03.080763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754331723.103392   29916 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754331723.110460   29916 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-04 18:22:03.133128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "!!!You are using `YOLOv5Head` with num_classes == 1. The loss_cls will be 0. This is a normal phenomenon.\n",
            "08/04 18:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "08/04 18:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_load_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "before_train:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(9           ) YOLOv5ParamSchedulerHook           \n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_save_checkpoint:\n",
            "(49          ) EMAHook                            \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DetVisualizationHook               \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(49          ) EMAHook                            \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) TextLoggerHook                     \n",
            " -------------------- \n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "  0% 0/348 [00:00<?, ?it/s]08/04 18:22:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "08/04 18:22:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "100% 348/348 [00:03<00:00, 90.26it/s] \n",
            "08/04 18:22:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.976\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.782\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.675\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.676\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n",
            "08/04 18:22:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.618 0.976 0.782 -1.000 0.333 0.621\n",
            "{'coco/bbox_mAP': 0.618, 'coco/bbox_mAP_50': 0.976, 'coco/bbox_mAP_75': 0.782, 'coco/bbox_mAP_s': -1.0, 'coco/bbox_mAP_m': 0.333, 'coco/bbox_mAP_l': 0.621}\n",
            "FPS: 220.607939 fram/s\n"
          ]
        }
      ],
      "source": [
        "!sscma.inference configs/swift_yolo/swift_yolo_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=BokChoy_Disease_Swift-YOLO_96 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=100  \\\n",
        "    height=96 \\\n",
        "    width=96 \\\n",
        "    data_root=BokChoy_Disease_Swift-YOLO_96/dataset/ \\\n",
        "    load_from=BokChoy_Disease_Swift-YOLO_96/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJVHh7-u5zfW"
      },
      "source": [
        "## 🤖 Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mwnSKk55zfX",
        "outputId": "117dece0-8f4b-4deb-ec74-d8c4898d578b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'BokChoy_Disease_Swift-YOLO_96/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%ls -lh BokChoy_Disease_Swift-YOLO_96/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fFYahed5zfX"
      },
      "source": [
        "### Thanks for Trying Out SSCMA 🎉\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ✨ on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}